{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_dict = {}\n",
    "id_dict = {}\n",
    "word_count_dict = {}\n",
    "country_set = set()\n",
    "\n",
    "# pulls text IDs, country codes, document types, and word counts from the excel sheet,\n",
    "# using it to divide the documents into a dictionary by ID\n",
    "sources_df = pd.read_excel(\"./text/sampleSources.xlsx\", sheet_name=\"texts\")\n",
    "for text_id, (country_code, doc_type), word_count in [(l[0], tuple(l[1].split()), l[2]) for l in sources_df[[\"textID\", \"country|genre\", \"# words\"]].values.tolist()]:\n",
    "    with open(f\"./text/w_{country_code.lower()}_{doc_type.lower()}.txt\", 'r',\n",
    "              encoding=\"utf-8\") as file:\n",
    "        # add each text_id to id_dict\n",
    "        if f\"{country_code}_{doc_type}\" not in id_dict:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"] = [text_id]\n",
    "        else:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"].append(text_id)\n",
    "        # makes country code set\n",
    "        country_set.add(country_code)\n",
    "        # finds correct text_id and adds every line in the document to the dictionary\n",
    "        IS_DOC = False\n",
    "        lines = file.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith(f\"##{text_id}\"):\n",
    "                IS_DOC = True\n",
    "            elif line.strip().startswith(\"##\"):\n",
    "                IS_DOC = False\n",
    "            if IS_DOC:\n",
    "                if text_id not in doc_dict:\n",
    "                    doc_dict[text_id] = [w.lower() for w in line.split()]\n",
    "                else:\n",
    "                    doc_dict[text_id] += [w.lower() for w in line.split()]\n",
    "        # adds word count to dictionary\n",
    "        word_count_dict[text_id] = word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "# make a counter for every word in the corpus\n",
    "vocab = Counter({})\n",
    "vocab['<UNK>'] = 0\n",
    "for doc in doc_dict.values():\n",
    "    for word in doc:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "\n",
    "# make a dictionary of sets for every country and record every word used by each country\n",
    "# also make a word count for every country\n",
    "vocab_sets = {country_code:set() for country_code in country_set}\n",
    "country_word_counts = Counter({country_code:0 for country_code in country_set})\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        for word in doc_dict[text_id]:\n",
    "            vocab_sets[country_code].add(word)\n",
    "        country_word_counts[country_code] += word_count_dict[text_id]\n",
    "\n",
    "# make new vocabulary sets, removing words that appear in less than\n",
    "# 25% and 50% of the countries datasets\n",
    "vocab_25 = vocab.copy()\n",
    "vocab_50 = vocab.copy()\n",
    "for word in vocab:\n",
    "    COUNTRY_COUNT = 0\n",
    "    for country_code in country_set:\n",
    "        if word in vocab_sets[country_code]:\n",
    "            COUNTRY_COUNT+=1\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.25:\n",
    "        del vocab_25[word]\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.5:\n",
    "        del vocab_50[word]\n",
    "\n",
    "# Replace any words that appear in less than 25% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_25 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_25.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_25:\n",
    "            doc_dict_25[text_id][i] = '<UNK>'\n",
    "            vocab_25['<UNK>'] += 1\n",
    "\n",
    "# Replace any words that appear in less than 50% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_50 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_50.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_50:\n",
    "            doc_dict_50[text_id][i] = '<UNK>'\n",
    "            vocab_50['<UNK>'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# make a dataframe with each version of the dataset with their country labels\n",
    "texts = []\n",
    "texts_25 = []\n",
    "texts_50 = []\n",
    "country_labels = []\n",
    "\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        texts.append(\" \".join(doc_dict[text_id]))\n",
    "        texts_25.append(\" \".join(doc_dict_25[text_id]))\n",
    "        texts_50.append(\" \".join(doc_dict_50[text_id]))\n",
    "        country_labels.append(country_code)\n",
    "\n",
    "data = {\n",
    "    'texts': texts,\n",
    "    'texts_25': texts_25,\n",
    "    'texts_50': texts_50,\n",
    "    'country_labels': country_labels\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['texts'])\n",
    "X_25 = vectorizer.fit_transform(df['texts_25'])\n",
    "X_50 = vectorizer.fit_transform(df['texts_50'])\n",
    "y = df['country_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_binary_classifiers(model_type, X_train, y_train, progress_updates=True):\n",
    "   # choose classifier and make a dictionary of models for every country\n",
    "    if model_type == \"rf\":\n",
    "        model_dict = {c:RandomForestClassifier(random_state=3, class_weight=\"balanced\") for c in country_set}\n",
    "    elif model_type == \"mlp\":\n",
    "        model_dict = {c:MLPClassifier(random_state=3) for c in country_set}\n",
    "    elif model_type == \"lr\":\n",
    "        model_dict = {c:LogisticRegression(max_iter=2000, class_weight=\"balanced\") for c in country_set}\n",
    "    elif model_type == \"nb\":\n",
    "        model_dict = {c:MultinomialNB() for c in country_set}\n",
    "    \n",
    "    for country in model_dict:\n",
    "        # make a copy of y and replace country labels with 0 or 1 depending on current country\n",
    "        y_train_binary = y_train.tolist()\n",
    "        for i, label in enumerate(y_train_binary):\n",
    "            if label != country:\n",
    "                y_train_binary[i] = 0\n",
    "            else:\n",
    "                y_train_binary[i] = 1\n",
    "        model_dict[country].fit(X_train, y_train_binary)\n",
    "        if progress_updates:\n",
    "            print(\".\",end=\" \")\n",
    "    if progress_updates:\n",
    "        print()\n",
    "        \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bc_predict_proba(model_dict, test):\n",
    "    probabilities = {c:0 for c in country_set}\n",
    "    for country in model_dict:\n",
    "            probabilities[country] = model_dict[country].predict_proba(test)[0][1]\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_breakdown(model_dict, X_test, y_test, print_output=False):\n",
    "    # makes a dictionary of probability Counters for every country label for each country's documents\n",
    "    most_probable_country = {c:Counter({c:0 for c in country_set}) for c in country_set}\n",
    "    for test_num, test in enumerate(X_test):\n",
    "        for country, probability in bc_predict_proba(model_dict, test).items():\n",
    "            most_probable_country[y_test.tolist()[test_num]][country] += probability\n",
    "    # Either returns or prints the results\n",
    "    if print_output:\n",
    "        for country in most_probable_country:\n",
    "            print(f\"{country}: {\" \".join([country for country, _ in most_probable_country[country].most_common(5)])}\")\n",
    "    else:\n",
    "        return most_probable_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_accuracy(y_pred, y_test):\n",
    "    country_accuracies = {c:0 for c in country_set}\n",
    "    country_test_count = Counter(y_test)\n",
    "    for i, country in enumerate(y_test):\n",
    "        if country == y_pred[i]:\n",
    "            country_accuracies[country]+=1\n",
    "    country_accuracies = {country:country_accuracies[country]/country_test_count[country] for country in country_accuracies}\n",
    "\n",
    "    return country_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tries(model_dict, X_test, y_test, print_output=False):\n",
    "    \"\"\"\n",
    "    Takes the model and testing data.\n",
    "    Returns average tries needed to return the right label,\n",
    "    average tries per country, and number of tests per country.\n",
    "    \"\"\"\n",
    "    probabilities = []\n",
    "    for test in X_test:\n",
    "            probabilities.append(bc_predict_proba(model_dict, test).values())     \n",
    "\n",
    "    # Matches each country label to its probability in a dataframe\n",
    "    df = pd.DataFrame(probabilities, columns=bc_predict_proba(model_dict, X_test[0]).keys())\n",
    "\n",
    "    # Sorts each probability distribution for highest probability\n",
    "    # and records the number of iterations needed to get to the right label\n",
    "    country_try_count = {c:0 for c in country_set}\n",
    "    country_test_count = Counter(y_test)\n",
    "    for i in range(len(df)):\n",
    "        for try_count, (country_code, _) in enumerate(sorted(df.iloc[i].to_dict().items(), key=lambda item: item[1], reverse=True)):\n",
    "            if country_code == y_test.tolist()[i]:\n",
    "                country_try_count[country_code] += try_count+1\n",
    "                break\n",
    "    \n",
    "    # Averages the country try count by number of tests\n",
    "    country_try_count = {country:country_try_count[country]/country_test_count[country] for country in country_try_count}\n",
    "    # Computes overal average try count\n",
    "    avg_tries = sum(country_try_count.values())/len(country_try_count)\n",
    "    \n",
    "    # Either returns or prints the results\n",
    "    if print_output:\n",
    "        for country, try_count in sorted(country_try_count.items(), key=lambda item: item[1]):\n",
    "            print(country, f\"{try_count:.1f} tries\", f\"({country_test_count[country]} tests)\")\n",
    "        print(\"Average number of tries:\", avg_tries)\n",
    "    else:\n",
    "        return avg_tries, country_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_binary_classifiers(model_dict, X_test, y_test):\n",
    "    results = []\n",
    "    y_pred = []\n",
    "    for i, test in enumerate(X_test):\n",
    "        probabilities = Counter({})\n",
    "        for country in model_dict:\n",
    "            probabilities[country] = model_dict[country].predict_proba(test)[0][1]\n",
    "        results.append(int(probabilities.most_common(1)[0][0] == y_test.tolist()[i]))\n",
    "        y_pred.append(probabilities.most_common(1)[0][0])\n",
    "    \n",
    "    most_probable_country = probability_breakdown(model_dict, X_test, y_test)\n",
    "    avg_tries, country_test_count = average_tries(model_dict, X_test, y_test)\n",
    "    country_accuracy = average_accuracy(y_pred, y_test)\n",
    "\n",
    "    print(f\"Accuracy: {sum(results)/len(results)}\")\n",
    "    print(f\"Average tries: {avg_tries}\")\n",
    "    for country, accuracy in sorted(country_accuracy.items(), key=lambda item: item[1], reverse=True):\n",
    "        most_similar_five = \" \".join([country for country, _ in most_probable_country[country].most_common(5)])\n",
    "        print(f\"{country}: {accuracy*100:4.1f}% accuracy\", f\"({country_test_count[country]:3d} tests) | {most_similar_five}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_binary_classifiers(model_type, dataset = \"full\"):\n",
    "    if dataset == \"full\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, stratify=y)\n",
    "    elif dataset == \"25%\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_25, y, test_size=0.2, random_state=3, stratify=y)\n",
    "    elif dataset == \"50%\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_50, y, test_size=0.2, random_state=3, stratify=y)\n",
    "    \n",
    "    model_dict = train_binary_classifiers(model_type, X_train, y_train)\n",
    "    test_binary_classifiers(model_dict, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.3333333333333333\n",
      "Average tries: 7.185838630323924\n",
      "US: 52.9% accuracy ( 68 tests) | US GB CA NZ IN\n",
      "GB: 50.0% accuracy ( 68 tests) | GB US AU NG IN\n",
      "IE: 38.9% accuracy ( 18 tests) | IE GB US PH CA\n",
      "LK: 37.5% accuracy (  8 tests) | LK GB US NG NZ\n",
      "TZ: 33.3% accuracy (  6 tests) | TZ KE HK IN IE\n",
      "JM: 28.6% accuracy (  7 tests) | US ZA JM NZ SG\n",
      "HK: 28.6% accuracy (  7 tests) | HK CA GB JM US\n",
      "BD: 28.6% accuracy (  7 tests) | BD GB IN CA PK\n",
      "AU: 23.1% accuracy ( 26 tests) | US AU GB NZ IN\n",
      "NZ: 21.4% accuracy ( 14 tests) | GB NZ NG US CA\n",
      "IN: 17.6% accuracy ( 17 tests) | GB IN US IE TZ\n",
      "CA: 17.4% accuracy ( 23 tests) | GB US CA AU NZ\n",
      "KE: 14.3% accuracy (  7 tests) | GB KE US PH IE\n",
      "GH: 14.3% accuracy (  7 tests) | US GB KE CA AU\n",
      "NG: 14.3% accuracy (  7 tests) | GH IN ZA GB AU\n",
      "ZA: 12.5% accuracy (  8 tests) | GB AU US ZA CA\n",
      "SG: 12.5% accuracy (  8 tests) | SG IN US PH GB\n",
      "PK: 11.1% accuracy (  9 tests) | US PK GB LK IN\n",
      "PH:  0.0% accuracy (  8 tests) | GB CA US AU JM\n",
      "MY:  0.0% accuracy (  7 tests) | US GB IN SG HK\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.3242424242424242\n",
      "Average tries: 7.336063723148122\n",
      "US: 51.5% accuracy ( 68 tests) | US GB CA NZ IN\n",
      "GB: 45.6% accuracy ( 68 tests) | GB US AU NG IN\n",
      "HK: 42.9% accuracy (  7 tests) | HK CA US IN GB\n",
      "BD: 42.9% accuracy (  7 tests) | BD GB CA IN MY\n",
      "IE: 38.9% accuracy ( 18 tests) | IE GB US PH NZ\n",
      "TZ: 33.3% accuracy (  6 tests) | TZ KE IN IE HK\n",
      "KE: 28.6% accuracy (  7 tests) | GB KE US PH IE\n",
      "LK: 25.0% accuracy (  8 tests) | GB LK US NG IN\n",
      "SG: 25.0% accuracy (  8 tests) | SG US IN PH GB\n",
      "IN: 23.5% accuracy ( 17 tests) | GB IN US ZA IE\n",
      "NZ: 21.4% accuracy ( 14 tests) | GB NG NZ PH US\n",
      "AU: 19.2% accuracy ( 26 tests) | US AU GB NZ NG\n",
      "GH: 14.3% accuracy (  7 tests) | US GB KE CA AU\n",
      "NG: 14.3% accuracy (  7 tests) | GH GB IN AU CA\n",
      "JM: 14.3% accuracy (  7 tests) | US JM ZA GB NZ\n",
      "CA: 13.0% accuracy ( 23 tests) | GB US CA AU IE\n",
      "ZA: 12.5% accuracy (  8 tests) | GB AU US CA ZA\n",
      "PK: 11.1% accuracy (  9 tests) | US GB AU IN LK\n",
      "PH:  0.0% accuracy (  8 tests) | GB CA US JM AU\n",
      "MY:  0.0% accuracy (  7 tests) | US GB CA HK SG\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.3\n",
      "Average tries: 7.607437060665961\n",
      "US: 52.9% accuracy ( 68 tests) | US GB CA IN NZ\n",
      "GB: 47.1% accuracy ( 68 tests) | GB US AU NG IN\n",
      "HK: 42.9% accuracy (  7 tests) | HK CA IN US JM\n",
      "IE: 38.9% accuracy ( 18 tests) | IE GB US ZA NZ\n",
      "TZ: 33.3% accuracy (  6 tests) | TZ IN KE HK IE\n",
      "SG: 25.0% accuracy (  8 tests) | SG GB IN PH US\n",
      "NZ: 21.4% accuracy ( 14 tests) | GB NZ NG US JM\n",
      "AU: 19.2% accuracy ( 26 tests) | US AU GB NG NZ\n",
      "KE: 14.3% accuracy (  7 tests) | GB KE PH US IE\n",
      "JM: 14.3% accuracy (  7 tests) | ZA JM US MY GB\n",
      "BD: 14.3% accuracy (  7 tests) | GB CA US PK BD\n",
      "ZA: 12.5% accuracy (  8 tests) | GB AU CA US ZA\n",
      "IN: 11.8% accuracy ( 17 tests) | GB IN IE ZA US\n",
      "PK: 11.1% accuracy (  9 tests) | US GB AU PK IN\n",
      "CA:  8.7% accuracy ( 23 tests) | GB US CA AU IE\n",
      "PH:  0.0% accuracy (  8 tests) | GB CA US JM AU\n",
      "GH:  0.0% accuracy (  7 tests) | GB US CA KE AU\n",
      "LK:  0.0% accuracy (  8 tests) | GB US NG TZ GH\n",
      "NG:  0.0% accuracy (  7 tests) | GH GB IN AU CA\n",
      "MY:  0.0% accuracy (  7 tests) | GB US GH NZ LK\n"
     ]
    }
   ],
   "source": [
    "train_test_binary_classifiers(\"lr\")\n",
    "train_test_binary_classifiers(\"lr\", \"25%\")\n",
    "train_test_binary_classifiers(\"lr\", \"50%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.27575757575757576\n",
      "Average tries: 7.782404876666385\n",
      "US: 61.8% accuracy ( 68 tests) | US GB CA AU IN\n",
      "GB: 61.8% accuracy ( 68 tests) | GB US AU CA IE\n",
      "SG: 12.5% accuracy (  8 tests) | GB US SG AU CA\n",
      "IN: 11.8% accuracy ( 17 tests) | GB US IN CA AU\n",
      "IE: 11.1% accuracy ( 18 tests) | GB US IE AU CA\n",
      "CA:  4.3% accuracy ( 23 tests) | US GB CA AU IE\n",
      "AU:  3.8% accuracy ( 26 tests) | GB US AU CA IE\n",
      "KE:  0.0% accuracy (  7 tests) | GB US AU CA IE\n",
      "ZA:  0.0% accuracy (  8 tests) | US GB AU CA NZ\n",
      "PK:  0.0% accuracy (  9 tests) | GB US IN AU PK\n",
      "TZ:  0.0% accuracy (  6 tests) | US GB CA AU IN\n",
      "PH:  0.0% accuracy (  8 tests) | GB US AU CA NZ\n",
      "GH:  0.0% accuracy (  7 tests) | GB US AU CA NZ\n",
      "LK:  0.0% accuracy (  8 tests) | GB US IE IN LK\n",
      "NG:  0.0% accuracy (  7 tests) | US GB CA AU NG\n",
      "NZ:  0.0% accuracy ( 14 tests) | GB US AU CA NZ\n",
      "JM:  0.0% accuracy (  7 tests) | US GB NZ AU CA\n",
      "HK:  0.0% accuracy (  7 tests) | US GB AU CA HK\n",
      "BD:  0.0% accuracy (  7 tests) | GB US AU IN CA\n",
      "MY:  0.0% accuracy (  7 tests) | US GB AU CA PK\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.30303030303030304\n",
      "Average tries: 8.256527067348678\n",
      "GB: 60.3% accuracy ( 68 tests) | GB US AU CA IE\n",
      "US: 58.8% accuracy ( 68 tests) | US GB CA AU IE\n",
      "IE: 38.9% accuracy ( 18 tests) | GB US IE AU CA\n",
      "TZ: 16.7% accuracy (  6 tests) | US GB IE AU CA\n",
      "GH: 14.3% accuracy (  7 tests) | GB US CA AU IE\n",
      "HK: 14.3% accuracy (  7 tests) | US GB CA AU HK\n",
      "SG: 12.5% accuracy (  8 tests) | US GB CA AU IE\n",
      "AU: 11.5% accuracy ( 26 tests) | GB US AU CA IN\n",
      "PK: 11.1% accuracy (  9 tests) | GB US AU CA IN\n",
      "CA:  8.7% accuracy ( 23 tests) | US GB CA AU PK\n",
      "NZ:  7.1% accuracy ( 14 tests) | GB US AU NZ CA\n",
      "IN:  5.9% accuracy ( 17 tests) | GB US IN CA AU\n",
      "KE:  0.0% accuracy (  7 tests) | GB US AU CA NZ\n",
      "ZA:  0.0% accuracy (  8 tests) | US GB AU IE CA\n",
      "PH:  0.0% accuracy (  8 tests) | US GB CA AU IE\n",
      "LK:  0.0% accuracy (  8 tests) | GB US AU IE CA\n",
      "NG:  0.0% accuracy (  7 tests) | US GB CA AU NZ\n",
      "JM:  0.0% accuracy (  7 tests) | GB US CA AU NZ\n",
      "BD:  0.0% accuracy (  7 tests) | GB US IN AU CA\n",
      "MY:  0.0% accuracy (  7 tests) | US GB AU CA IN\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.25757575757575757\n",
      "Average tries: 8.754383269472784\n",
      "US: 58.8% accuracy ( 68 tests) | US GB CA AU IE\n",
      "GB: 50.0% accuracy ( 68 tests) | GB US AU CA IE\n",
      "HK: 14.3% accuracy (  7 tests) | US GB CA AU HK\n",
      "SG: 12.5% accuracy (  8 tests) | GB US CA SG AU\n",
      "AU: 11.5% accuracy ( 26 tests) | GB US AU CA IE\n",
      "PK: 11.1% accuracy (  9 tests) | GB US IN CA AU\n",
      "IE: 11.1% accuracy ( 18 tests) | GB US IE AU CA\n",
      "NZ:  7.1% accuracy ( 14 tests) | GB US AU NZ CA\n",
      "IN:  5.9% accuracy ( 17 tests) | GB US IN CA AU\n",
      "CA:  4.3% accuracy ( 23 tests) | US GB CA AU NZ\n",
      "KE:  0.0% accuracy (  7 tests) | GB US AU CA IN\n",
      "ZA:  0.0% accuracy (  8 tests) | US GB AU IN IE\n",
      "TZ:  0.0% accuracy (  6 tests) | US GB AU CA IE\n",
      "PH:  0.0% accuracy (  8 tests) | GB US CA AU IE\n",
      "GH:  0.0% accuracy (  7 tests) | GB US AU CA IE\n",
      "LK:  0.0% accuracy (  8 tests) | GB US AU IE CA\n",
      "NG:  0.0% accuracy (  7 tests) | US GB CA AU NZ\n",
      "JM:  0.0% accuracy (  7 tests) | US GB IE AU NZ\n",
      "BD:  0.0% accuracy (  7 tests) | US GB AU CA IE\n",
      "MY:  0.0% accuracy (  7 tests) | US GB AU CA PK\n"
     ]
    }
   ],
   "source": [
    "train_test_binary_classifiers(\"rf\")\n",
    "train_test_binary_classifiers(\"rf\", \"25%\")\n",
    "train_test_binary_classifiers(\"rf\", \"50%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.3484848484848485\n",
      "Average tries: 7.263232561698035\n",
      "GB: 69.1% accuracy ( 68 tests) | GB US AU IN NZ\n",
      "US: 57.4% accuracy ( 68 tests) | US GB AU CA HK\n",
      "LK: 37.5% accuracy (  8 tests) | LK US GB AU IE\n",
      "HK: 28.6% accuracy (  7 tests) | CA IN US AU HK\n",
      "BD: 28.6% accuracy (  7 tests) | BD US ZA GB CA\n",
      "AU: 26.9% accuracy ( 26 tests) | US GB AU IE CA\n",
      "IE: 22.2% accuracy ( 18 tests) | GB IE US AU CA\n",
      "TZ: 16.7% accuracy (  6 tests) | US TZ NG GB ZA\n",
      "GH: 14.3% accuracy (  7 tests) | GB US AU GH NZ\n",
      "NZ: 14.3% accuracy ( 14 tests) | GB US NZ AU IN\n",
      "CA: 13.0% accuracy ( 23 tests) | GB US CA BD IE\n",
      "SG: 12.5% accuracy (  8 tests) | SG US GB AU LK\n",
      "IN: 11.8% accuracy ( 17 tests) | GB IN US AU CA\n",
      "PK: 11.1% accuracy (  9 tests) | GB PK LK IN CA\n",
      "KE:  0.0% accuracy (  7 tests) | GB US KE IE NZ\n",
      "ZA:  0.0% accuracy (  8 tests) | GB AU NZ US IN\n",
      "PH:  0.0% accuracy (  8 tests) | GB AU PK US LK\n",
      "NG:  0.0% accuracy (  7 tests) | GB AU US TZ CA\n",
      "JM:  0.0% accuracy (  7 tests) | US GB AU CA NZ\n",
      "MY:  0.0% accuracy (  7 tests) | US IE GB TZ NZ\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.3181818181818182\n",
      "Average tries: 7.957340606253649\n",
      "GB: 67.6% accuracy ( 68 tests) | GB US AU IE CA\n",
      "US: 55.9% accuracy ( 68 tests) | US GB AU CA IE\n",
      "IE: 27.8% accuracy ( 18 tests) | US GB IE AU CA\n",
      "LK: 25.0% accuracy (  8 tests) | GB US LK IE AU\n",
      "AU: 23.1% accuracy ( 26 tests) | US GB AU IE CA\n",
      "GH: 14.3% accuracy (  7 tests) | US AU GB GH BD\n",
      "HK: 14.3% accuracy (  7 tests) | CA IN US NZ AU\n",
      "BD: 14.3% accuracy (  7 tests) | US ZA BD GB CA\n",
      "SG: 12.5% accuracy (  8 tests) | GB US IE LK AU\n",
      "PK: 11.1% accuracy (  9 tests) | GB CA PK IN KE\n",
      "CA:  8.7% accuracy ( 23 tests) | GB US CA IE BD\n",
      "IN:  5.9% accuracy ( 17 tests) | GB IN US CA IE\n",
      "KE:  0.0% accuracy (  7 tests) | GB US IE CA AU\n",
      "ZA:  0.0% accuracy (  8 tests) | GB AU NZ US CA\n",
      "TZ:  0.0% accuracy (  6 tests) | US GB AU TZ NG\n",
      "PH:  0.0% accuracy (  8 tests) | GB AU CA PK US\n",
      "NG:  0.0% accuracy (  7 tests) | GB AU CA US TZ\n",
      "NZ:  0.0% accuracy ( 14 tests) | GB US AU IE NZ\n",
      "JM:  0.0% accuracy (  7 tests) | GB US AU NZ CA\n",
      "MY:  0.0% accuracy (  7 tests) | US IE GB AU IN\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.30606060606060603\n",
      "Average tries: 8.795257202658098\n",
      "GB: 64.7% accuracy ( 68 tests) | GB US AU NZ IE\n",
      "US: 57.4% accuracy ( 68 tests) | US GB AU CA IE\n",
      "NZ: 21.4% accuracy ( 14 tests) | GB NZ AU US IE\n",
      "AU: 19.2% accuracy ( 26 tests) | US AU GB IE CA\n",
      "CA: 17.4% accuracy ( 23 tests) | GB US CA BD AU\n",
      "IE: 16.7% accuracy ( 18 tests) | US GB AU IE CA\n",
      "GH: 14.3% accuracy (  7 tests) | US AU GB BD NZ\n",
      "SG: 12.5% accuracy (  8 tests) | US AU IE GB BD\n",
      "IN:  5.9% accuracy ( 17 tests) | GB US IN AU CA\n",
      "KE:  0.0% accuracy (  7 tests) | GB US IE AU TZ\n",
      "ZA:  0.0% accuracy (  8 tests) | AU GB NZ TZ US\n",
      "PK:  0.0% accuracy (  9 tests) | GB IN PK AU CA\n",
      "TZ:  0.0% accuracy (  6 tests) | US AU GB NG GH\n",
      "PH:  0.0% accuracy (  8 tests) | GB AU CA US IE\n",
      "LK:  0.0% accuracy (  8 tests) | US GB AU IE LK\n",
      "NG:  0.0% accuracy (  7 tests) | GB US AU CA IE\n",
      "JM:  0.0% accuracy (  7 tests) | US GB AU CA NZ\n",
      "HK:  0.0% accuracy (  7 tests) | CA IN AU NZ US\n",
      "BD:  0.0% accuracy (  7 tests) | US GB NG ZA BD\n",
      "MY:  0.0% accuracy (  7 tests) | US CA IE PK GB\n"
     ]
    }
   ],
   "source": [
    "train_test_binary_classifiers(\"mlp\")\n",
    "train_test_binary_classifiers(\"mlp\", \"25%\")\n",
    "train_test_binary_classifiers(\"mlp\", \"50%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
