{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_dict = {}\n",
    "id_dict = {}\n",
    "word_count_dict = {}\n",
    "country_set = set()\n",
    "\n",
    "# pulls text IDs, country codes, document types, and word counts from the excel sheet,\n",
    "# using it to divide the documents into a dictionary by ID\n",
    "sources_df = pd.read_excel(\"./text/sampleSources.xlsx\", sheet_name=\"texts\")\n",
    "for text_id, (country_code, doc_type), word_count in [(l[0], tuple(l[1].split()), l[2]) for l in sources_df[[\"textID\", \"country|genre\", \"# words\"]].values.tolist()]:\n",
    "    with open(f\"./text/w_{country_code.lower()}_{doc_type.lower()}.txt\", 'r',\n",
    "              encoding=\"utf-8\") as file:\n",
    "        # add each text_id to id_dict\n",
    "        if f\"{country_code}_{doc_type}\" not in id_dict:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"] = [text_id]\n",
    "        else:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"].append(text_id)\n",
    "        # makes country code set\n",
    "        country_set.add(country_code)\n",
    "        # finds correct text_id and adds every line in the document to the dictionary\n",
    "        IS_DOC = False\n",
    "        lines = file.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith(f\"##{text_id}\"):\n",
    "                IS_DOC = True\n",
    "            elif line.strip().startswith(\"##\"):\n",
    "                IS_DOC = False\n",
    "            if IS_DOC:\n",
    "                if text_id not in doc_dict:\n",
    "                    doc_dict[text_id] = [w.lower() for w in line.split()]\n",
    "                else:\n",
    "                    doc_dict[text_id] += [w.lower() for w in line.split()]\n",
    "        # adds word count to dictionary\n",
    "        word_count_dict[text_id] = word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "# make a counter for every word in the corpus\n",
    "vocab = Counter({})\n",
    "vocab['<UNK>'] = 0\n",
    "for doc in doc_dict.values():\n",
    "    for word in doc:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "\n",
    "# make a dictionary of sets for every country and record every word used by each country\n",
    "# also make a word count for every country\n",
    "vocab_sets = {country_code:set() for country_code in country_set}\n",
    "country_word_counts = Counter({country_code:0 for country_code in country_set})\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        for word in doc_dict[text_id]:\n",
    "            vocab_sets[country_code].add(word)\n",
    "        country_word_counts[country_code] += word_count_dict[text_id]\n",
    "\n",
    "# make new vocabulary sets, removing words that appear in less than\n",
    "# 25% and 50% of the countries datasets\n",
    "vocab_25 = vocab.copy()\n",
    "vocab_50 = vocab.copy()\n",
    "for word in vocab:\n",
    "    COUNTRY_COUNT = 0\n",
    "    for country_code in country_set:\n",
    "        if word in vocab_sets[country_code]:\n",
    "            COUNTRY_COUNT+=1\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.25:\n",
    "        del vocab_25[word]\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.5:\n",
    "        del vocab_50[word]\n",
    "\n",
    "# Replace any words that appear in less than 25% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_25 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_25.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_25:\n",
    "            doc_dict_25[text_id][i] = '<UNK>'\n",
    "            vocab_25['<UNK>'] += 1\n",
    "\n",
    "# Replace any words that appear in less than 50% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_50 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_50.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_50:\n",
    "            doc_dict_50[text_id][i] = '<UNK>'\n",
    "            vocab_50['<UNK>'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# make a dataframe with each version of the dataset with their country labels\n",
    "texts = []\n",
    "texts_25 = []\n",
    "texts_50 = []\n",
    "country_labels = []\n",
    "\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        texts.append(\" \".join(doc_dict[text_id]))\n",
    "        texts_25.append(\" \".join(doc_dict_25[text_id]))\n",
    "        texts_50.append(\" \".join(doc_dict_50[text_id]))\n",
    "        country_labels.append(country_code)\n",
    "\n",
    "data = {\n",
    "    'texts': texts,\n",
    "    'texts_25': texts_25,\n",
    "    'texts_50': texts_50,\n",
    "    'country_labels': country_labels\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['texts'])\n",
    "X_25 = vectorizer.fit_transform(df['texts_25'])\n",
    "X_50 = vectorizer.fit_transform(df['texts_50'])\n",
    "y = df['country_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_binary_classifiers(model_type, X_train, y_train, progress_updates=True):\n",
    "   # choose classifier and make a dictionary of models for every country\n",
    "    if model_type == \"rf\":\n",
    "        model_dict = {c:RandomForestClassifier(random_state=3, class_weight=\"balanced\") for c in country_set}\n",
    "    elif model_type == \"mlp\":\n",
    "        model_dict = {c:MLPClassifier(random_state=3) for c in country_set}\n",
    "    elif model_type == \"lr\":\n",
    "        model_dict = {c:LogisticRegression(max_iter=2000, class_weight=\"balanced\") for c in country_set}\n",
    "    elif model_type == \"nb\":\n",
    "        model_dict = {c:MultinomialNB() for c in country_set}\n",
    "    \n",
    "    for country in model_dict:\n",
    "        # make a copy of y and replace country labels with 0 or 1 depending on current country\n",
    "        y_train_binary = y_train.tolist()\n",
    "        for i, label in enumerate(y_train_binary):\n",
    "            if label != country:\n",
    "                y_train_binary[i] = 0\n",
    "            else:\n",
    "                y_train_binary[i] = 1\n",
    "        model_dict[country].fit(X_train, y_train_binary)\n",
    "        if progress_updates:\n",
    "            print(\".\",end=\" \")\n",
    "    if progress_updates:\n",
    "        print()\n",
    "        \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bc_predict_proba(model_dict, test):\n",
    "    probabilities = {c:0 for c in country_set}\n",
    "    for country in model_dict:\n",
    "            probabilities[country] = model_dict[country].predict_proba(test)[0][1]\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_breakdown(model_dict, X_test, y_test, print_output=False):\n",
    "    # makes a dictionary of probability Counters for every country label for each country's documents\n",
    "    most_probable_country = {c:Counter({c:0 for c in country_set}) for c in country_set}\n",
    "    for test_num, test in enumerate(X_test):\n",
    "        for country, probability in bc_predict_proba(model_dict, test).items():\n",
    "            most_probable_country[y_test.tolist()[test_num]][country] += probability\n",
    "    # Either returns or prints the results\n",
    "    if print_output:\n",
    "        for country in most_probable_country:\n",
    "            print(f\"{country}: {\" \".join([country for country, _ in most_probable_country[country].most_common(5)])}\")\n",
    "    else:\n",
    "        return most_probable_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tries(model_dict, X_test, y_test, print_output=False):\n",
    "    \"\"\"\n",
    "    Takes the model and testing data.\n",
    "    Returns average tries needed to return the right label,\n",
    "    average tries per country, and number of tests per country.\n",
    "    \"\"\"\n",
    "    probabilities = []\n",
    "    for test in X_test:\n",
    "            probabilities.append(bc_predict_proba(model_dict, test).values())     \n",
    "\n",
    "    # Matches each country label to its probability in a dataframe\n",
    "    df = pd.DataFrame(probabilities, columns=bc_predict_proba(model_dict, X_test[0]).keys())\n",
    "\n",
    "    # Sorts each probability distribution for highest probability\n",
    "    # and records the number of iterations needed to get to the right label\n",
    "    country_try_count = {c:0 for c in country_set}\n",
    "    country_test_count = Counter(y_test)\n",
    "    for i in range(len(df)):\n",
    "        for try_count, (country_code, _) in enumerate(sorted(df.iloc[i].to_dict().items(), key=lambda item: item[1], reverse=True)):\n",
    "            if country_code == y_test.tolist()[i]:\n",
    "                country_try_count[country_code] += try_count+1\n",
    "                break\n",
    "    \n",
    "    # Averages the country try count by number of tests\n",
    "    country_try_count = {country:country_try_count[country]/country_test_count[country] for country in country_try_count}\n",
    "    # Computes overal average try count\n",
    "    avg_tries = sum(country_try_count.values())/len(country_try_count)\n",
    "    \n",
    "    # Either returns or prints the results\n",
    "    if print_output:\n",
    "        for country, try_count in sorted(country_try_count.items(), key=lambda item: item[1]):\n",
    "            print(country, f\"{try_count:.1f} tries\", f\"({country_test_count[country]} tests)\")\n",
    "        print(\"Average number of tries:\", avg_tries)\n",
    "    else:\n",
    "        return avg_tries, country_try_count, country_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_binary_classifiers(model_dict, X_test, y_test):\n",
    "    results = []\n",
    "    for i, test in enumerate(X_test):\n",
    "        probabilities = Counter({})\n",
    "        for country in model_dict:\n",
    "            probabilities[country] = model_dict[country].predict_proba(test)[0][1]\n",
    "        results.append(int(probabilities.most_common(1)[0][0] == y_test.tolist()[i]))\n",
    "    \n",
    "    most_probable_country = probability_breakdown(model_dict, X_test, y_test)\n",
    "    avg_tries, country_try_count, country_test_count = average_tries(model_dict, X_test, y_test)\n",
    "\n",
    "    print(f\"Accuracy: {sum(results)/len(results)}\")\n",
    "    print(f\"Average tries: {avg_tries}\")\n",
    "    for country, try_count in sorted(country_try_count.items(), key=lambda item: item[1]):\n",
    "        most_similar_five = \" \".join([country for country, _ in most_probable_country[country].most_common(5)])\n",
    "        print(f\"{country}: {try_count:4.1f} tries\", f\"({country_test_count[country]:3d} tests) | {most_similar_five}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_binary_classifiers(model_type, dataset = \"full\"):\n",
    "    if dataset == \"full\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, stratify=y)\n",
    "    elif dataset == \"25%\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_25, y, test_size=0.2, random_state=3, stratify=y)\n",
    "    elif dataset == \"50%\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_50, y, test_size=0.2, random_state=3, stratify=y)\n",
    "    \n",
    "    model_dict = train_binary_classifiers(model_type, X_train, y_train)\n",
    "    test_binary_classifiers(model_dict, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.296969696969697\n",
      "Average tries: 6.879611691011144\n",
      "US:  2.2 tries ( 56 tests) | US GB NZ IN CA\n",
      "GB:  3.2 tries ( 59 tests) | GB US CA IE AU\n",
      "CA:  3.3 tries ( 29 tests) | US GB CA IE AU\n",
      "NZ:  4.9 tries ( 15 tests) | GB US NZ LK BD\n",
      "IE:  4.9 tries ( 16 tests) | IE US GB CA AU\n",
      "HK:  5.4 tries (  7 tests) | GB AU MY US IE\n",
      "AU:  5.5 tries ( 31 tests) | AU GB US IE CA\n",
      "NG:  6.2 tries (  6 tests) | US PK GH GB NG\n",
      "LK:  6.3 tries ( 11 tests) | GB LK AU US IN\n",
      "IN:  6.5 tries ( 25 tests) | IN GB US CA PK\n",
      "PK:  6.8 tries ( 12 tests) | GB CA PK US SG\n",
      "KE:  6.9 tries (  8 tests) | GB CA KE PH US\n",
      "TZ:  7.4 tries (  8 tests) | GB TZ US CA IN\n",
      "SG:  7.8 tries (  5 tests) | US GB SG CA IN\n",
      "MY:  8.4 tries (  8 tests) | GB US MY IE AU\n",
      "GH:  8.5 tries (  8 tests) | GB GH NG KE PK\n",
      "BD:  9.5 tries (  6 tests) | US GB JM AU IN\n",
      "JM:  9.7 tries (  6 tests) | US AU IE GH SG\n",
      "ZA:  9.7 tries (  9 tests) | US CA GB AU IN\n",
      "PH: 14.6 tries (  5 tests) | GB US IN IE NZ\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.2818181818181818\n",
      "Average tries: 7.116709301253737\n",
      "US:  2.6 tries ( 56 tests) | US GB IN NZ AU\n",
      "GB:  3.1 tries ( 59 tests) | GB US CA PH AU\n",
      "CA:  4.2 tries ( 29 tests) | US GB CA IE HK\n",
      "NZ:  5.1 tries ( 15 tests) | GB US NZ LK CA\n",
      "IE:  5.3 tries ( 16 tests) | IE GB US CA AU\n",
      "AU:  5.7 tries ( 31 tests) | GB AU US JM IE\n",
      "LK:  6.1 tries ( 11 tests) | GB LK AU US PH\n",
      "IN:  6.2 tries ( 25 tests) | IN US GB PK CA\n",
      "NG:  6.8 tries (  6 tests) | US PK GH AU GB\n",
      "HK:  6.9 tries (  7 tests) | GB US MY AU HK\n",
      "TZ:  7.0 tries (  8 tests) | GB TZ US GH IN\n",
      "KE:  7.0 tries (  8 tests) | GB CA KE JM PH\n",
      "PK:  7.1 tries ( 12 tests) | GB PK CA US IE\n",
      "SG:  7.4 tries (  5 tests) | IN US SG GB MY\n",
      "GH:  8.1 tries (  8 tests) | GB GH NG KE PK\n",
      "MY:  8.6 tries (  8 tests) | GB US MY SG GH\n",
      "BD:  9.2 tries (  6 tests) | US GB JM IN NZ\n",
      "ZA:  9.9 tries (  9 tests) | US CA GB IE PH\n",
      "JM: 11.7 tries (  6 tests) | US AU IE JM SG\n",
      "PH: 14.4 tries (  5 tests) | GB IN IE CA US\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.2636363636363636\n",
      "Average tries: 7.556479341952738\n",
      "US:  2.7 tries ( 56 tests) | US GB AU IN CA\n",
      "GB:  3.5 tries ( 59 tests) | GB US CA PH AU\n",
      "CA:  4.4 tries ( 29 tests) | US GB CA IE PK\n",
      "NZ:  5.5 tries ( 15 tests) | GB US NZ LK CA\n",
      "IE:  6.1 tries ( 16 tests) | GB IE US AU CA\n",
      "AU:  6.1 tries ( 31 tests) | GB AU US JM IE\n",
      "HK:  6.6 tries (  7 tests) | GB US MY AU BD\n",
      "IN:  6.6 tries ( 25 tests) | IN US GB CA PK\n",
      "SG:  6.6 tries (  5 tests) | IN MY US SG GB\n",
      "TZ:  6.8 tries (  8 tests) | IN GB TZ US GH\n",
      "PK:  7.2 tries ( 12 tests) | GB PK CA US LK\n",
      "KE:  7.6 tries (  8 tests) | CA GB US JM PH\n",
      "NG:  8.5 tries (  6 tests) | US GH PK AU GB\n",
      "MY:  8.8 tries (  8 tests) | GB US GH MY SG\n",
      "GH:  8.9 tries (  8 tests) | GB US KE NG PK\n",
      "LK:  9.4 tries ( 11 tests) | GB US AU PH LK\n",
      "BD:  9.7 tries (  6 tests) | US GB JM IN NZ\n",
      "ZA: 10.0 tries (  9 tests) | US CA AU GB PH\n",
      "JM: 11.7 tries (  6 tests) | US AU IE JM SG\n",
      "PH: 14.8 tries (  5 tests) | GB IE IN TZ CA\n"
     ]
    }
   ],
   "source": [
    "train_test_binary_classifiers(\"lr\")\n",
    "train_test_binary_classifiers(\"lr\", \"25%\")\n",
    "train_test_binary_classifiers(\"lr\", \"50%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.2787878787878788\n",
      "Average tries: 7.184698756278768\n",
      "US:  1.3 tries ( 56 tests) | US GB AU CA IE\n",
      "GB:  1.3 tries ( 59 tests) | GB US AU CA IE\n",
      "AU:  3.3 tries ( 31 tests) | GB US AU CA IE\n",
      "CA:  4.4 tries ( 29 tests) | US GB CA AU IE\n",
      "IE:  4.8 tries ( 16 tests) | GB US IE CA AU\n",
      "JM:  5.5 tries (  6 tests) | GB US AU IE JM\n",
      "NG:  6.0 tries (  6 tests) | GB US NG CA AU\n",
      "NZ:  6.7 tries ( 15 tests) | GB US AU CA NZ\n",
      "HK:  6.9 tries (  7 tests) | US GB AU CA IE\n",
      "IN:  6.9 tries ( 25 tests) | GB US IN AU CA\n",
      "TZ:  7.2 tries (  8 tests) | GB US CA AU IE\n",
      "PK:  7.4 tries ( 12 tests) | US GB PK AU IN\n",
      "BD:  7.7 tries (  6 tests) | GB US AU IE NZ\n",
      "LK:  7.8 tries ( 11 tests) | GB US CA AU IE\n",
      "GH:  8.5 tries (  8 tests) | GB US CA AU IE\n",
      "SG:  9.6 tries (  5 tests) | GB US AU CA SG\n",
      "PH: 10.0 tries (  5 tests) | GB US CA AU IE\n",
      "KE: 11.6 tries (  8 tests) | GB US CA AU IE\n",
      "ZA: 12.2 tries (  9 tests) | GB US IE AU CA\n",
      "MY: 14.5 tries (  8 tests) | US GB CA AU IE\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.2606060606060606\n",
      "Average tries: 7.806266532274047\n",
      "US:  1.3 tries ( 56 tests) | US GB AU CA IE\n",
      "GB:  1.4 tries ( 59 tests) | GB US AU CA IE\n",
      "AU:  3.5 tries ( 31 tests) | GB US AU CA IE\n",
      "IE:  3.6 tries ( 16 tests) | GB US IE CA AU\n",
      "CA:  4.6 tries ( 29 tests) | US GB CA AU IE\n",
      "IN:  5.5 tries ( 25 tests) | GB US IN AU CA\n",
      "SG:  6.4 tries (  5 tests) | GB US AU SG IE\n",
      "LK:  6.7 tries ( 11 tests) | US GB CA LK AU\n",
      "JM:  7.0 tries (  6 tests) | US GB AU IE CA\n",
      "NZ:  7.1 tries ( 15 tests) | GB US AU NZ CA\n",
      "HK:  7.6 tries (  7 tests) | US GB CA AU IE\n",
      "GH:  8.4 tries (  8 tests) | US GB AU CA GH\n",
      "PK:  8.5 tries ( 12 tests) | US GB PK IN CA\n",
      "KE:  9.0 tries (  8 tests) | GB US CA AU IE\n",
      "PH: 10.4 tries (  5 tests) | GB US CA AU IE\n",
      "MY: 11.2 tries (  8 tests) | US GB AU CA IE\n",
      "NG: 12.5 tries (  6 tests) | US GB CA AU IE\n",
      "ZA: 13.4 tries (  9 tests) | GB US AU CA IE\n",
      "TZ: 13.9 tries (  8 tests) | GB US IE CA AU\n",
      "BD: 14.2 tries (  6 tests) | GB US AU IE CA\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.2787878787878788\n",
      "Average tries: 8.10895617024585\n",
      "US:  1.2 tries ( 56 tests) | US GB CA AU IE\n",
      "GB:  1.4 tries ( 59 tests) | GB US AU CA IE\n",
      "IE:  4.2 tries ( 16 tests) | GB US IE CA AU\n",
      "AU:  4.5 tries ( 31 tests) | GB US AU IE CA\n",
      "CA:  4.6 tries ( 29 tests) | US GB CA AU IE\n",
      "SG:  5.2 tries (  5 tests) | GB US AU SG CA\n",
      "IN:  6.1 tries ( 25 tests) | GB US AU IN CA\n",
      "NZ:  7.1 tries ( 15 tests) | US GB AU CA NZ\n",
      "HK:  8.1 tries (  7 tests) | GB US CA AU IE\n",
      "PK:  8.3 tries ( 12 tests) | US GB PK CA AU\n",
      "JM:  9.0 tries (  6 tests) | US GB AU IE CA\n",
      "ZA:  9.8 tries (  9 tests) | GB US AU IE IN\n",
      "LK:  9.9 tries ( 11 tests) | GB US AU CA IE\n",
      "PH: 10.2 tries (  5 tests) | GB US AU CA IE\n",
      "NG: 11.2 tries (  6 tests) | US GB IE CA BD\n",
      "KE: 11.5 tries (  8 tests) | GB US CA IE AU\n",
      "BD: 11.7 tries (  6 tests) | GB US AU IE NZ\n",
      "TZ: 12.4 tries (  8 tests) | GB US CA IE NZ\n",
      "GH: 12.8 tries (  8 tests) | US GB AU CA IE\n",
      "MY: 12.9 tries (  8 tests) | US GB AU IE CA\n"
     ]
    }
   ],
   "source": [
    "train_test_binary_classifiers(\"rf\")\n",
    "train_test_binary_classifiers(\"rf\", \"25%\")\n",
    "train_test_binary_classifiers(\"rf\", \"50%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.3\n",
      "Average tries: 7.280144423993468\n",
      "US:  1.7 tries ( 56 tests) | US GB CA AU IE\n",
      "GB:  2.0 tries ( 59 tests) | GB US CA IE AU\n",
      "AU:  2.5 tries ( 31 tests) | GB AU US IE TZ\n",
      "IE:  2.6 tries ( 16 tests) | IE GB US CA AU\n",
      "CA:  3.7 tries ( 29 tests) | US GB CA IE AU\n",
      "IN:  5.9 tries ( 25 tests) | IN GB US CA IE\n",
      "NG:  6.2 tries (  6 tests) | US IE NG GB LK\n",
      "SG:  6.8 tries (  5 tests) | GB SG US IE AU\n",
      "NZ:  7.1 tries ( 15 tests) | GB US IE AU CA\n",
      "LK:  7.1 tries ( 11 tests) | US AU GB IE IN\n",
      "TZ:  7.1 tries (  8 tests) | US GB TZ AU IE\n",
      "PK:  7.2 tries ( 12 tests) | GB PK US CA IE\n",
      "MY:  7.8 tries (  8 tests) | GB IE US AU MY\n",
      "HK:  8.6 tries (  7 tests) | GB IE US AU CA\n",
      "GH:  9.2 tries (  8 tests) | GB AU US CA GH\n",
      "KE:  9.6 tries (  8 tests) | GB CA US AU KE\n",
      "JM: 10.8 tries (  6 tests) | US GB GH AU SG\n",
      "PH: 12.2 tries (  5 tests) | GB US IE AU IN\n",
      "ZA: 13.2 tries (  9 tests) | US IE GB AU TZ\n",
      "BD: 14.3 tries (  6 tests) | GB US IE ZA AU\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.2636363636363636\n",
      "Average tries: 7.852166431027124\n",
      "GB:  1.8 tries ( 59 tests) | GB US CA AU IE\n",
      "US:  1.9 tries ( 56 tests) | US GB CA IE AU\n",
      "AU:  2.9 tries ( 31 tests) | US GB AU IE LK\n",
      "IE:  3.6 tries ( 16 tests) | US IE GB CA AU\n",
      "CA:  4.5 tries ( 29 tests) | US GB AU IN NZ\n",
      "IN:  6.0 tries ( 25 tests) | GB US IN CA MY\n",
      "SG:  6.0 tries (  5 tests) | SG GB US IE AU\n",
      "PK:  6.1 tries ( 12 tests) | PK GB US CA IE\n",
      "NZ:  6.1 tries ( 15 tests) | US GB AU IE NZ\n",
      "LK:  6.7 tries ( 11 tests) | AU US GB IN LK\n",
      "MY:  7.9 tries (  8 tests) | GB US AU IE LK\n",
      "GH:  8.1 tries (  8 tests) | GB CA US AU GH\n",
      "NG:  8.8 tries (  6 tests) | US GB LK IE NG\n",
      "TZ: 10.4 tries (  8 tests) | GB US PH NZ AU\n",
      "HK: 10.4 tries (  7 tests) | GB AU US IN MY\n",
      "KE: 11.0 tries (  8 tests) | GB CA US AU KE\n",
      "JM: 12.7 tries (  6 tests) | US GB SG AU GH\n",
      "PH: 13.2 tries (  5 tests) | GB AU US IN SG\n",
      "BD: 14.0 tries (  6 tests) | US GB AU NZ MY\n",
      "ZA: 14.8 tries (  9 tests) | US GB AU NZ TZ\n",
      ". . . . . . . . . . . . . . . . . . . . \n",
      "Accuracy: 0.2606060606060606\n",
      "Average tries: 8.325854142122298\n",
      "US:  1.8 tries ( 56 tests) | US GB CA IE IN\n",
      "GB:  2.1 tries ( 59 tests) | GB US CA PH AU\n",
      "AU:  3.2 tries ( 31 tests) | GB US AU IE LK\n",
      "CA:  4.5 tries ( 29 tests) | US GB IN AU NZ\n",
      "IE:  4.9 tries ( 16 tests) | GB US IE CA IN\n",
      "PK:  5.8 tries ( 12 tests) | PK US GB CA MY\n",
      "MY:  6.4 tries (  8 tests) | GB AU US MY IE\n",
      "SG:  6.4 tries (  5 tests) | GB US AU SG IE\n",
      "IN:  6.8 tries ( 25 tests) | GB US IN CA NZ\n",
      "LK:  7.4 tries ( 11 tests) | US AU GB IE CA\n",
      "NZ:  7.8 tries ( 15 tests) | GB US IE NZ AU\n",
      "TZ:  8.1 tries (  8 tests) | GB US PH IE CA\n",
      "GH:  9.4 tries (  8 tests) | GB US CA AU GH\n",
      "HK: 10.3 tries (  7 tests) | GB US CA AU IN\n",
      "NG: 11.0 tries (  6 tests) | GB IE US LK NG\n",
      "KE: 11.8 tries (  8 tests) | GB US CA AU NZ\n",
      "PH: 14.4 tries (  5 tests) | GB AU IN PK US\n",
      "JM: 14.7 tries (  6 tests) | US AU GB SG IN\n",
      "BD: 14.7 tries (  6 tests) | US GB AU NZ MY\n",
      "ZA: 15.1 tries (  9 tests) | US AU GB NZ TZ\n"
     ]
    }
   ],
   "source": [
    "train_test_binary_classifiers(\"mlp\")\n",
    "train_test_binary_classifiers(\"mlp\", \"25%\")\n",
    "train_test_binary_classifiers(\"mlp\", \"50%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
