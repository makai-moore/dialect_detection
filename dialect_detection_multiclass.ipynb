{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_dict = {}\n",
    "id_dict = {}\n",
    "word_count_dict = {}\n",
    "country_set = set()\n",
    "\n",
    "# pulls text IDs, country codes, document types, and word counts from the excel sheet,\n",
    "# using it to divide the documents into a dictionary by ID\n",
    "sources_df = pd.read_excel(\"./text/sampleSources.xlsx\", sheet_name=\"texts\")\n",
    "for text_id, (country_code, doc_type), word_count in [(l[0], tuple(l[1].split()), l[2]) for l in sources_df[[\"textID\", \"country|genre\", \"# words\"]].values.tolist()]:\n",
    "    with open(f\"./text/w_{country_code.lower()}_{doc_type.lower()}.txt\", 'r',\n",
    "              encoding=\"utf-8\") as file:\n",
    "        # add each text_id to id_dict\n",
    "        if f\"{country_code}_{doc_type}\" not in id_dict:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"] = [text_id]\n",
    "        else:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"].append(text_id)\n",
    "        # makes country code set\n",
    "        country_set.add(country_code)\n",
    "        # finds correct text_id and adds every line in the document to the dictionary\n",
    "        IS_DOC = False\n",
    "        lines = file.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith(f\"##{text_id}\"):\n",
    "                IS_DOC = True\n",
    "            elif line.strip().startswith(\"##\"):\n",
    "                IS_DOC = False\n",
    "            if IS_DOC:\n",
    "                if text_id not in doc_dict:\n",
    "                    doc_dict[text_id] = [w.lower() for w in line.split()]\n",
    "                else:\n",
    "                    doc_dict[text_id] += [w.lower() for w in line.split()]\n",
    "        # adds word count to dictionary\n",
    "        word_count_dict[text_id] = word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "# make a counter for every word in the corpus\n",
    "vocab = Counter({})\n",
    "vocab['<UNK>'] = 0\n",
    "for doc in doc_dict.values():\n",
    "    for word in doc:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "\n",
    "# make a dictionary of sets for every country and record every word used by each country\n",
    "# also make a word count for every country\n",
    "vocab_sets = {country_code:set() for country_code in country_set}\n",
    "country_word_counts = Counter({country_code:0 for country_code in country_set})\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        for word in doc_dict[text_id]:\n",
    "            vocab_sets[country_code].add(word)\n",
    "        country_word_counts[country_code] += word_count_dict[text_id]\n",
    "\n",
    "# make new vocabulary sets, removing words that appear in less than\n",
    "# 25% and 50% of the countries datasets\n",
    "vocab_25 = vocab.copy()\n",
    "vocab_50 = vocab.copy()\n",
    "for word in vocab:\n",
    "    COUNTRY_COUNT = 0\n",
    "    for country_code in country_set:\n",
    "        if word in vocab_sets[country_code]:\n",
    "            COUNTRY_COUNT+=1\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.25:\n",
    "        del vocab_25[word]\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.5:\n",
    "        del vocab_50[word]\n",
    "\n",
    "# Replace any words that appear in less than 25% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_25 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_25.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_25:\n",
    "            doc_dict_25[text_id][i] = '<UNK>'\n",
    "            vocab_25['<UNK>'] += 1\n",
    "\n",
    "# Replace any words that appear in less than 50% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_50 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_50.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_50:\n",
    "            doc_dict_50[text_id][i] = '<UNK>'\n",
    "            vocab_50['<UNK>'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# make a dataframe with each version of the dataset with their country labels\n",
    "texts = []\n",
    "texts_25 = []\n",
    "texts_50 = []\n",
    "country_labels = []\n",
    "\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        texts.append(\" \".join(doc_dict[text_id]))\n",
    "        texts_25.append(\" \".join(doc_dict_25[text_id]))\n",
    "        texts_50.append(\" \".join(doc_dict_50[text_id]))\n",
    "        country_labels.append(country_code)\n",
    "\n",
    "data = {\n",
    "    'texts': texts,\n",
    "    'texts_25': texts_25,\n",
    "    'texts_50': texts_50,\n",
    "    'country_labels': country_labels\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['texts'])\n",
    "X_25 = vectorizer.fit_transform(df['texts_25'])\n",
    "X_50 = vectorizer.fit_transform(df['texts_50'])\n",
    "y = df['country_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_breakdown(model, X_test, y_test):\n",
    "    # makes a dictionary of probability Counters for every country label for each country's documents\n",
    "    most_probable_country = {c:Counter({c:0 for c in country_set}) for c in country_set}\n",
    "    for test_num, probabilities in enumerate(model.predict_proba(X_test)):\n",
    "        for i, probability in enumerate(probabilities):\n",
    "            most_probable_country[y_test.tolist()[test_num]][model.classes_[i]] += probability  \n",
    "\n",
    "    return most_probable_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_accuracy(y_pred, y_test):\n",
    "    country_accuracies = {c:0 for c in country_set}\n",
    "    country_test_count = Counter(y_test)\n",
    "    for i, country in enumerate(y_test):\n",
    "        if country == y_pred[i]:\n",
    "            country_accuracies[country]+=1\n",
    "    country_accuracies = {country:country_accuracies[country]/country_test_count[country] for country in country_accuracies}\n",
    "\n",
    "    return country_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tries(model, X_test, y_test, print_output=False):\n",
    "    \"\"\"\n",
    "    Takes the model and testing data.\n",
    "    Returns average tries needed to return the right label,\n",
    "    average tries per country, and number of tests per country.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Matches each country label to its probability in a dataframe\n",
    "    df = pd.DataFrame(model.predict_proba(X_test).tolist(), columns=model.classes_.tolist())\n",
    "\n",
    "    # Sorts each probability distribution for highest probability\n",
    "    # and records the number of iterations needed to get to the right label\n",
    "    country_try_count = {c:0 for c in country_set}\n",
    "    country_test_count = Counter(y_test)\n",
    "    for i in range(len(df)):\n",
    "        for try_count, (country_code, _) in enumerate(sorted(df.iloc[i].to_dict().items(), key=lambda item: item[1], reverse=True)):\n",
    "            if country_code == y_test.tolist()[i]:\n",
    "                country_try_count[country_code] += try_count+1\n",
    "                break\n",
    "    \n",
    "    # Averages the country try count by number of tests\n",
    "    country_try_count = {country:country_try_count[country]/country_test_count[country] for country in country_try_count}\n",
    "    # Computes overal average try count\n",
    "    avg_tries = sum(country_try_count.values())/len(country_try_count)\n",
    "    \n",
    "    # Either returns or prints the results\n",
    "    if print_output:\n",
    "        for country, try_count in sorted(country_try_count.items(), key=lambda item: item[1]):\n",
    "            print(country, f\"{try_count:.1f} tries\", f\"({country_test_count[country]} tests)\")\n",
    "        print(\"Average number of tries:\", avg_tries)\n",
    "    else:\n",
    "        return avg_tries, country_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def average_performance(model, X_dataset, y_dataset = y, random_states=10, undersampling=False, scrambling=False):\n",
    "    \"\"\"\n",
    "    Takes the model, dataset, and number of random test splits to test.\n",
    "    Prints average accuracy and tries between all test splits of the model.\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    tries = []\n",
    "    total_country_test_count = {c:0 for c in country_set}\n",
    "    avg_country_accuracies = {c:0 for c in country_set}\n",
    "    avg_most_probable_country = {c:Counter({c:0 for c in country_set}) for c in country_set}\n",
    "    \n",
    "    if scrambling:\n",
    "        random.seed = 3\n",
    "        y_scrambled = y_dataset.tolist()\n",
    "        random.shuffle(y_scrambled)\n",
    "        y_dataset = pd.Series(y_scrambled)\n",
    "\n",
    "    # trains models on the specified number of random splits\n",
    "    for r in range(random_states):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size=0.2, random_state=r, stratify=y_dataset)\n",
    "        # undersampling\n",
    "        if undersampling:\n",
    "            X_train, y_train = RandomUnderSampler(random_state=3).fit_resample(X_train, y_train)\n",
    "        model.fit(X_train, y_train)\n",
    "        # computes accuracies\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        country_accuracies = average_accuracy(y_pred, y_test)\n",
    "        # computes overall and country try counts\n",
    "        avg_tries, country_test_count = average_tries(model, X_test, y_test)\n",
    "        tries.append(avg_tries)\n",
    "        # computes similar countries\n",
    "        most_probable_country = probability_breakdown(model, X_test, y_test)\n",
    "        for country in country_set:\n",
    "            avg_country_accuracies[country] += country_accuracies[country]\n",
    "            total_country_test_count[country] += country_test_count[country]\n",
    "            avg_most_probable_country[country] += most_probable_country[country]\n",
    "        print(\".\",end=\" \")\n",
    "    print()\n",
    "    \n",
    "    print(\"Average Accuracy:\", np.mean(accuracies))\n",
    "    print(\"Averaged Average tries:\", np.mean(tries))\n",
    "    # Sorts country try counts and prints them in order\n",
    "    avg_country_accuracies = {country:avg_country_accuracies[country]/(random_states) for country in avg_country_accuracies}\n",
    "    for country, accuracy in sorted(avg_country_accuracies.items(), key=lambda item: item[1], reverse=True):\n",
    "        most_similar_five = \" \".join([country for country, _ in avg_most_probable_country[country].most_common(5)])\n",
    "        print(f\"{country}: {accuracy*100:4.1f}% accuracy\", f\"({total_country_test_count[country]:3d} tests) | {most_similar_five}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.30454545454545456\n",
      "Averaged Average tries: 7.225151297977385\n",
      "US: 46.5% accuracy (680 tests) | US GB CA AU IN\n",
      "GB: 45.6% accuracy (680 tests) | GB US AU CA IN\n",
      "AU: 26.9% accuracy (260 tests) | AU GB US IE CA\n",
      "IE: 25.6% accuracy (180 tests) | IE US GB CA AU\n",
      "PK: 24.4% accuracy ( 90 tests) | PK US IN GB AU\n",
      "JM: 22.9% accuracy ( 70 tests) | GB JM US CA NZ\n",
      "LK: 21.2% accuracy ( 80 tests) | LK GB US AU CA\n",
      "IN: 21.2% accuracy (170 tests) | GB IN US CA NZ\n",
      "HK: 20.0% accuracy ( 70 tests) | HK US GB CA AU\n",
      "NZ: 18.6% accuracy (140 tests) | GB NZ US AU IN\n",
      "GH: 18.6% accuracy ( 70 tests) | GH GB US KE AU\n",
      "BD: 18.6% accuracy ( 70 tests) | BD GB IE IN US\n",
      "CA: 18.3% accuracy (230 tests) | US GB CA AU IE\n",
      "KE: 15.7% accuracy ( 70 tests) | US KE GB CA AU\n",
      "TZ: 15.0% accuracy ( 60 tests) | GB TZ US KE IN\n",
      "SG: 13.8% accuracy ( 80 tests) | US SG GB IN PH\n",
      "NG: 12.9% accuracy ( 70 tests) | GB US NG AU CA\n",
      "PH: 11.2% accuracy ( 80 tests) | GB US AU CA SG\n",
      "ZA: 10.0% accuracy ( 80 tests) | US GB CA ZA AU\n",
      "MY: 10.0% accuracy ( 70 tests) | GB US MY AU CA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.28454545454545455\n",
      "Averaged Average tries: 7.368112075655235\n",
      "US: 44.3% accuracy (680 tests) | US GB CA AU IN\n",
      "GB: 43.2% accuracy (680 tests) | GB US AU CA IN\n",
      "IE: 26.7% accuracy (180 tests) | IE GB US CA AU\n",
      "AU: 26.2% accuracy (260 tests) | AU US GB CA IE\n",
      "GH: 21.4% accuracy ( 70 tests) | GH GB US KE AU\n",
      "IN: 21.2% accuracy (170 tests) | IN GB US CA AU\n",
      "PK: 21.1% accuracy ( 90 tests) | PK US IN GB AU\n",
      "BD: 20.0% accuracy ( 70 tests) | BD GB IN IE KE\n",
      "NZ: 19.3% accuracy (140 tests) | GB NZ US AU IN\n",
      "SG: 17.5% accuracy ( 80 tests) | US SG GB IN PH\n",
      "CA: 14.3% accuracy (230 tests) | US GB CA AU IE\n",
      "KE: 14.3% accuracy ( 70 tests) | US KE GB CA PH\n",
      "HK: 14.3% accuracy ( 70 tests) | US HK GB CA IN\n",
      "LK: 13.8% accuracy ( 80 tests) | LK GB US AU IN\n",
      "TZ: 13.3% accuracy ( 60 tests) | GB TZ US IE KE\n",
      "MY: 11.4% accuracy ( 70 tests) | GB US MY AU SG\n",
      "NG: 10.0% accuracy ( 70 tests) | GB US NG AU GH\n",
      "PH:  7.5% accuracy ( 80 tests) | GB US AU SG CA\n",
      "JM:  7.1% accuracy ( 70 tests) | GB US JM CA IN\n",
      "ZA:  6.2% accuracy ( 80 tests) | GB US CA AU ZA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.2587878787878788\n",
      "Averaged Average tries: 7.81284926177829\n",
      "US: 42.1% accuracy (680 tests) | US GB CA AU IN\n",
      "GB: 40.3% accuracy (680 tests) | GB US AU CA IN\n",
      "AU: 28.8% accuracy (260 tests) | AU US GB CA NZ\n",
      "IE: 25.0% accuracy (180 tests) | IE GB US CA AU\n",
      "IN: 21.2% accuracy (170 tests) | IN GB US CA IE\n",
      "NZ: 18.6% accuracy (140 tests) | GB NZ US AU IN\n",
      "PK: 17.8% accuracy ( 90 tests) | PK US IN GB AU\n",
      "SG: 17.5% accuracy ( 80 tests) | US SG GB IN PH\n",
      "HK: 15.7% accuracy ( 70 tests) | US HK IN CA GB\n",
      "GH: 15.7% accuracy ( 70 tests) | GB US GH KE AU\n",
      "CA: 12.6% accuracy (230 tests) | US GB CA AU IN\n",
      "TZ: 11.7% accuracy ( 60 tests) | GB TZ US IE KE\n",
      "KE:  8.6% accuracy ( 70 tests) | US GB KE AU JM\n",
      "MY:  7.1% accuracy ( 70 tests) | GB US MY AU SG\n",
      "JM:  7.1% accuracy ( 70 tests) | GB US JM IN NZ\n",
      "ZA:  5.0% accuracy ( 80 tests) | GB CA US AU ZA\n",
      "PH:  3.8% accuracy ( 80 tests) | GB US AU SG CA\n",
      "LK:  1.2% accuracy ( 80 tests) | US GB AU IE CA\n",
      "BD:  0.0% accuracy ( 70 tests) | GB US IE IN KE\n",
      "NG:  0.0% accuracy ( 70 tests) | GB US AU TZ LK\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression model with class weights balanced\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "average_performance(model, X)\n",
    "average_performance(model, X_25)\n",
    "average_performance(model, X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.3418181818181818\n",
      "Averaged Average tries: 6.370949687567334\n",
      "US: 59.6% accuracy (680 tests) | US GB CA AU IN\n",
      "GB: 53.8% accuracy (680 tests) | GB US AU CA IN\n",
      "NG: 51.4% accuracy ( 70 tests) | US GB NG AU CA\n",
      "LK: 42.5% accuracy ( 80 tests) | GB US LK IN AU\n",
      "IE: 41.1% accuracy (180 tests) | GB US IE AU CA\n",
      "GH: 28.6% accuracy ( 70 tests) | US GB GH AU CA\n",
      "BD: 28.6% accuracy ( 70 tests) | US GB BD AU IN\n",
      "PK: 23.3% accuracy ( 90 tests) | GB US PK CA IN\n",
      "NZ: 22.9% accuracy (140 tests) | US GB NZ AU CA\n",
      "JM: 20.0% accuracy ( 70 tests) | US GB JM CA AU\n",
      "IN: 18.8% accuracy (170 tests) | GB US IN AU CA\n",
      "AU: 16.9% accuracy (260 tests) | US GB AU CA NZ\n",
      "MY: 10.0% accuracy ( 70 tests) | US GB MY AU CA\n",
      "SG:  7.5% accuracy ( 80 tests) | US GB SG AU CA\n",
      "HK:  7.1% accuracy ( 70 tests) | US GB HK AU CA\n",
      "TZ:  3.3% accuracy ( 60 tests) | US GB AU IE CA\n",
      "CA:  3.0% accuracy (230 tests) | US GB CA AU IN\n",
      "ZA:  2.5% accuracy ( 80 tests) | US GB AU CA ZA\n",
      "KE:  1.4% accuracy ( 70 tests) | US GB AU CA KE\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB AU CA PH\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.3472727272727273\n",
      "Averaged Average tries: 6.699211002126603\n",
      "US: 62.4% accuracy (680 tests) | US GB CA AU IN\n",
      "NG: 50.0% accuracy ( 70 tests) | US GB NG AU CA\n",
      "GB: 47.5% accuracy (680 tests) | US GB AU CA IN\n",
      "LK: 41.2% accuracy ( 80 tests) | GB US LK IN AU\n",
      "IE: 41.1% accuracy (180 tests) | IE GB US AU CA\n",
      "NZ: 37.1% accuracy (140 tests) | US GB NZ AU CA\n",
      "BD: 37.1% accuracy ( 70 tests) | US GB BD AU IN\n",
      "GH: 28.6% accuracy ( 70 tests) | US GB GH AU CA\n",
      "AU: 27.3% accuracy (260 tests) | US GB AU CA NZ\n",
      "PK: 21.1% accuracy ( 90 tests) | GB US PK IN CA\n",
      "IN: 16.5% accuracy (170 tests) | GB US IN AU CA\n",
      "SG: 12.5% accuracy ( 80 tests) | US GB SG AU CA\n",
      "HK:  8.6% accuracy ( 70 tests) | US GB HK AU CA\n",
      "MY:  8.6% accuracy ( 70 tests) | US GB MY AU CA\n",
      "CA:  7.0% accuracy (230 tests) | US GB CA AU IN\n",
      "TZ:  3.3% accuracy ( 60 tests) | US GB CA AU IE\n",
      "ZA:  1.2% accuracy ( 80 tests) | US GB AU CA IN\n",
      "KE:  0.0% accuracy ( 70 tests) | US GB AU CA KE\n",
      "JM:  0.0% accuracy ( 70 tests) | US GB CA AU IN\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.29727272727272724\n",
      "Averaged Average tries: 8.204259627485332\n",
      "US: 61.3% accuracy (680 tests) | US GB CA AU IN\n",
      "GB: 47.6% accuracy (680 tests) | GB US AU CA IN\n",
      "NZ: 36.4% accuracy (140 tests) | US GB NZ AU CA\n",
      "IE: 32.2% accuracy (180 tests) | US GB IE AU CA\n",
      "AU: 19.2% accuracy (260 tests) | US GB AU CA NZ\n",
      "IN: 17.6% accuracy (170 tests) | US GB IN AU CA\n",
      "PK: 16.7% accuracy ( 90 tests) | US GB PK IN CA\n",
      "HK: 12.9% accuracy ( 70 tests) | US GB HK AU CA\n",
      "SG:  8.8% accuracy ( 80 tests) | US GB SG AU CA\n",
      "GH:  8.6% accuracy ( 70 tests) | GB US AU CA ZA\n",
      "MY:  5.7% accuracy ( 70 tests) | US GB AU CA MY\n",
      "CA:  3.9% accuracy (230 tests) | US GB CA AU IE\n",
      "ZA:  1.2% accuracy ( 80 tests) | US GB AU CA IN\n",
      "KE:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB AU IN CA\n",
      "JM:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "TZ:  0.0% accuracy ( 60 tests) | US GB IE AU CA\n",
      "BD:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "NG:  0.0% accuracy ( 70 tests) | US GB CA AU IN\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB CA AU IN\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Classifier with class weights balanced\n",
    "rf_model = RandomForestClassifier(random_state=3, class_weight='balanced')\n",
    "average_performance(rf_model, X)\n",
    "average_performance(rf_model, X_25)\n",
    "average_performance(rf_model, X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.32757575757575763\n",
      "Averaged Average tries: 7.338455831608004\n",
      "US: 61.2% accuracy (680 tests) | US GB CA AU IN\n",
      "GB: 52.8% accuracy (680 tests) | GB US CA AU IN\n",
      "CA: 31.3% accuracy (230 tests) | US CA GB AU IN\n",
      "AU: 24.6% accuracy (260 tests) | US AU GB CA IE\n",
      "IN: 18.8% accuracy (170 tests) | GB US IN CA AU\n",
      "PK: 16.7% accuracy ( 90 tests) | GB US PK CA IN\n",
      "JM: 15.7% accuracy ( 70 tests) | US CA GB JM AU\n",
      "NG: 15.7% accuracy ( 70 tests) | GB AU US NG CA\n",
      "IE: 13.9% accuracy (180 tests) | GB US IE CA AU\n",
      "NZ: 13.6% accuracy (140 tests) | GB US NZ CA AU\n",
      "LK: 12.5% accuracy ( 80 tests) | GB US LK CA AU\n",
      "HK: 11.4% accuracy ( 70 tests) | US GB HK CA AU\n",
      "SG: 10.0% accuracy ( 80 tests) | US GB CA AU SG\n",
      "PH: 10.0% accuracy ( 80 tests) | GB US CA PH AU\n",
      "BD: 10.0% accuracy ( 70 tests) | GB US CA BD AU\n",
      "MY:  7.1% accuracy ( 70 tests) | US GB CA MY AU\n",
      "GH:  7.1% accuracy ( 70 tests) | GB US AU CA GH\n",
      "ZA:  3.8% accuracy ( 80 tests) | US GB CA AU JM\n",
      "KE:  2.9% accuracy ( 70 tests) | US GB CA AU NZ\n",
      "TZ:  1.7% accuracy ( 60 tests) | GB US CA AU TZ\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.29242424242424236\n",
      "Averaged Average tries: 7.490315038222647\n",
      "US: 54.7% accuracy (680 tests) | US GB CA AU IN\n",
      "GB: 47.6% accuracy (680 tests) | GB US CA AU IN\n",
      "PK: 27.8% accuracy ( 90 tests) | PK GB US CA IN\n",
      "AU: 23.1% accuracy (260 tests) | GB AU US CA IN\n",
      "IE: 21.7% accuracy (180 tests) | US GB IE CA AU\n",
      "SG: 17.5% accuracy ( 80 tests) | US GB SG AU CA\n",
      "BD: 15.7% accuracy ( 70 tests) | US GB BD IN CA\n",
      "NG: 15.7% accuracy ( 70 tests) | GB US NG AU CA\n",
      "IN: 15.3% accuracy (170 tests) | GB US IN CA AU\n",
      "CA: 15.2% accuracy (230 tests) | US GB CA AU IN\n",
      "GH: 14.3% accuracy ( 70 tests) | GB US GH AU CA\n",
      "PH: 10.0% accuracy ( 80 tests) | US GB CA AU PH\n",
      "ZA:  7.5% accuracy ( 80 tests) | US GB CA AU JM\n",
      "MY:  7.1% accuracy ( 70 tests) | US GB MY CA AU\n",
      "NZ:  7.1% accuracy (140 tests) | GB US NZ AU IN\n",
      "LK:  6.2% accuracy ( 80 tests) | GB US CA AU IN\n",
      "HK:  2.9% accuracy ( 70 tests) | US CA AU GB HK\n",
      "KE:  1.4% accuracy ( 70 tests) | US GB CA AU NZ\n",
      "JM:  1.4% accuracy ( 70 tests) | GB US CA AU IN\n",
      "TZ:  0.0% accuracy ( 60 tests) | GB US CA ZA IE\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.29272727272727267\n",
      "Averaged Average tries: 8.353704511068642\n",
      "GB: 52.8% accuracy (680 tests) | GB US CA AU IN\n",
      "US: 52.4% accuracy (680 tests) | US GB CA AU IE\n",
      "PK: 27.8% accuracy ( 90 tests) | PK US GB IN IE\n",
      "IE: 21.7% accuracy (180 tests) | GB US IE CA AU\n",
      "AU: 19.6% accuracy (260 tests) | GB US AU CA IE\n",
      "CA: 18.7% accuracy (230 tests) | US GB CA AU IE\n",
      "NZ: 17.1% accuracy (140 tests) | GB US NZ AU IN\n",
      "SG: 16.2% accuracy ( 80 tests) | US SG AU GB CA\n",
      "IN: 14.1% accuracy (170 tests) | GB US IN CA AU\n",
      "HK:  8.6% accuracy ( 70 tests) | US AU GB IE HK\n",
      "PH:  7.5% accuracy ( 80 tests) | US GB AU PH CA\n",
      "GH:  7.1% accuracy ( 70 tests) | GB US AU GH CA\n",
      "MY:  5.7% accuracy ( 70 tests) | GB US CA AU MY\n",
      "BD:  5.7% accuracy ( 70 tests) | GB US CA IE KE\n",
      "ZA:  5.0% accuracy ( 80 tests) | GB US AU CA ZA\n",
      "TZ:  1.7% accuracy ( 60 tests) | GB US CA IN ZA\n",
      "KE:  1.4% accuracy ( 70 tests) | GB US CA IN ZA\n",
      "NG:  1.4% accuracy ( 70 tests) | US GB AU CA TZ\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      "JM:  0.0% accuracy ( 70 tests) | GB US CA AU NZ\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Multi-layer Perceptron Model\n",
    "mlp_model = MLPClassifier(random_state=3)\n",
    "average_performance(mlp_model,X)\n",
    "average_performance(mlp_model,X_25)\n",
    "average_performance(mlp_model,X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.14242424242424243\n",
      "Averaged Average tries: 7.687717055607081\n",
      "HK: 25.7% accuracy ( 70 tests) | HK MY JM IE TZ\n",
      "LK: 25.0% accuracy ( 80 tests) | LK CA TZ PH KE\n",
      "BD: 24.3% accuracy ( 70 tests) | BD MY KE JM IN\n",
      "JM: 24.3% accuracy ( 70 tests) | JM ZA NZ PH IN\n",
      "PK: 23.3% accuracy ( 90 tests) | PK IN HK MY NG\n",
      "GH: 21.4% accuracy ( 70 tests) | GH KE NG TZ PH\n",
      "TZ: 18.3% accuracy ( 60 tests) | TZ KE GH AU IE\n",
      "SG: 17.5% accuracy ( 80 tests) | SG TZ PH IN NZ\n",
      "KE: 17.1% accuracy ( 70 tests) | KE PH TZ JM ZA\n",
      "NG: 15.7% accuracy ( 70 tests) | NG TZ GB GH KE\n",
      "IE: 15.0% accuracy (180 tests) | IE PH GB ZA CA\n",
      "MY: 14.3% accuracy ( 70 tests) | MY GH SG GB TZ\n",
      "IN: 14.1% accuracy (170 tests) | IN GB CA BD ZA\n",
      "ZA: 13.8% accuracy ( 80 tests) | ZA JM US GH IE\n",
      "GB: 12.9% accuracy (680 tests) | GB NZ CA PH IE\n",
      "NZ: 12.1% accuracy (140 tests) | PH NZ GB JM IE\n",
      "US: 11.3% accuracy (680 tests) | CA US GB PH IE\n",
      "AU: 11.2% accuracy (260 tests) | AU JM PH NG GB\n",
      "CA: 10.4% accuracy (230 tests) | CA US PH GB IN\n",
      "PH:  8.8% accuracy ( 80 tests) | SG PH JM KE CA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.1303030303030303\n",
      "Averaged Average tries: 7.764882667950123\n",
      "PK: 23.3% accuracy ( 90 tests) | PK HK IN NG GB\n",
      "BD: 22.9% accuracy ( 70 tests) | BD KE MY IN PK\n",
      "HK: 20.0% accuracy ( 70 tests) | HK MY IE PH JM\n",
      "GH: 20.0% accuracy ( 70 tests) | GH KE NG TZ PH\n",
      "SG: 18.8% accuracy ( 80 tests) | SG TZ PH MY US\n",
      "JM: 18.6% accuracy ( 70 tests) | JM ZA NZ PH IN\n",
      "IN: 17.6% accuracy (170 tests) | IN SG GB BD US\n",
      "TZ: 16.7% accuracy ( 60 tests) | TZ KE GH GB IE\n",
      "KE: 15.7% accuracy ( 70 tests) | KE PH TZ JM NG\n",
      "IE: 15.6% accuracy (180 tests) | IE HK CA PH GB\n",
      "LK: 15.0% accuracy ( 80 tests) | LK TZ PH CA IN\n",
      "MY: 14.3% accuracy ( 70 tests) | MY SG US GB GH\n",
      "NZ: 12.9% accuracy (140 tests) | PH NZ JM IE GB\n",
      "GB: 11.5% accuracy (680 tests) | GB CA NZ US JM\n",
      "US: 10.9% accuracy (680 tests) | CA US GB PH JM\n",
      "AU: 10.4% accuracy (260 tests) | AU JM NG GB IE\n",
      "ZA: 10.0% accuracy ( 80 tests) | ZA JM GH US IE\n",
      "NG: 10.0% accuracy ( 70 tests) | TZ NG GH HK GB\n",
      "CA:  7.8% accuracy (230 tests) | CA US PH GB TZ\n",
      "PH:  7.5% accuracy ( 80 tests) | SG JM PH GB CA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.11515151515151516\n",
      "Averaged Average tries: 8.186386041317306\n",
      "HK: 22.9% accuracy ( 70 tests) | HK MY JM IE TZ\n",
      "PK: 21.1% accuracy ( 90 tests) | PK HK IN GB CA\n",
      "SG: 17.5% accuracy ( 80 tests) | SG PH MY JM US\n",
      "JM: 17.1% accuracy ( 70 tests) | JM ZA NZ IE PH\n",
      "IN: 15.9% accuracy (170 tests) | IN BD IE GB ZA\n",
      "GH: 15.7% accuracy ( 70 tests) | GH KE NG TZ LK\n",
      "TZ: 15.0% accuracy ( 60 tests) | TZ GH KE LK HK\n",
      "NZ: 12.9% accuracy (140 tests) | PH NZ JM IN GB\n",
      "AU: 11.9% accuracy (260 tests) | AU JM NG GB BD\n",
      "IE: 11.7% accuracy (180 tests) | IE HK CA MY AU\n",
      "KE: 11.4% accuracy ( 70 tests) | KE PH TZ JM NG\n",
      "MY: 11.4% accuracy ( 70 tests) | MY SG AU GH GB\n",
      "GB: 11.3% accuracy (680 tests) | GB NZ CA IE PH\n",
      "US: 10.0% accuracy (680 tests) | CA US GB PH MY\n",
      "BD:  8.6% accuracy ( 70 tests) | KE MY IE LK BD\n",
      "CA:  7.8% accuracy (230 tests) | CA US PH GB IN\n",
      "ZA:  7.5% accuracy ( 80 tests) | ZA GH JM US LK\n",
      "LK:  5.0% accuracy ( 80 tests) | TZ PH NG IE CA\n",
      "PH:  5.0% accuracy ( 80 tests) | SG JM KE GH GB\n",
      "NG:  4.3% accuracy ( 70 tests) | TZ GH LK HK GB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression model with undersampling\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "average_performance(model, X, undersampling=True)\n",
    "average_performance(model, X_25, undersampling=True)\n",
    "average_performance(model, X_50, undersampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.22787878787878788\n",
      "Averaged Average tries: 6.6156307166121735\n",
      "NG: 70.0% accuracy ( 70 tests) | NG ZA KE GB JM\n",
      "LK: 55.0% accuracy ( 80 tests) | LK IN GB PH CA\n",
      "IE: 50.0% accuracy (180 tests) | IE PH GB CA ZA\n",
      "JM: 47.1% accuracy ( 70 tests) | JM PH GB ZA CA\n",
      "GH: 45.7% accuracy ( 70 tests) | GH TZ JM ZA PH\n",
      "BD: 42.9% accuracy ( 70 tests) | BD PK GB CA IE\n",
      "PK: 37.8% accuracy ( 90 tests) | PK CA GB BD IN\n",
      "NZ: 32.1% accuracy (140 tests) | NZ PH GB AU SG\n",
      "HK: 27.1% accuracy ( 70 tests) | HK SG PH AU TZ\n",
      "SG: 26.2% accuracy ( 80 tests) | SG PH JM GB US\n",
      "AU: 25.8% accuracy (260 tests) | AU GB PH CA US\n",
      "GB: 17.8% accuracy (680 tests) | GB PH CA US JM\n",
      "PH: 16.2% accuracy ( 80 tests) | PH SG GB ZA CA\n",
      "ZA: 15.0% accuracy ( 80 tests) | ZA GB US PH IN\n",
      "CA: 14.8% accuracy (230 tests) | CA GB US PH ZA\n",
      "KE: 14.3% accuracy ( 70 tests) | KE TZ ZA GB GH\n",
      "MY: 14.3% accuracy ( 70 tests) | MY GB PH AU US\n",
      "IN: 12.4% accuracy (170 tests) | IN GB LK BD PH\n",
      "TZ: 10.0% accuracy ( 60 tests) | TZ ZA GB JM IE\n",
      "US:  9.0% accuracy (680 tests) | GB US PH CA AU\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.2084848484848485\n",
      "Averaged Average tries: 6.8652492454618415\n",
      "NG: 61.4% accuracy ( 70 tests) | NG KE JM CA US\n",
      "LK: 55.0% accuracy ( 80 tests) | LK IN GB CA HK\n",
      "IE: 46.7% accuracy (180 tests) | IE GB JM PH US\n",
      "BD: 41.4% accuracy ( 70 tests) | BD JM IN PK ZA\n",
      "SG: 38.8% accuracy ( 80 tests) | SG JM PH GB CA\n",
      "PK: 37.8% accuracy ( 90 tests) | PK IN BD GB ZA\n",
      "NZ: 35.0% accuracy (140 tests) | NZ GB AU JM PH\n",
      "GH: 34.3% accuracy ( 70 tests) | GH TZ ZA JM KE\n",
      "HK: 25.7% accuracy ( 70 tests) | HK SG PH PK JM\n",
      "AU: 25.0% accuracy (260 tests) | AU GB NZ US JM\n",
      "CA: 17.0% accuracy (230 tests) | CA GB US PH JM\n",
      "JM: 15.7% accuracy ( 70 tests) | JM GB PH ZA HK\n",
      "TZ: 15.0% accuracy ( 60 tests) | TZ ZA KE GH GB\n",
      "MY: 14.3% accuracy ( 70 tests) | MY JM SG GB HK\n",
      "GB: 13.8% accuracy (680 tests) | GB US PH JM CA\n",
      "IN: 13.5% accuracy (170 tests) | IN LK BD GB JM\n",
      "KE: 12.9% accuracy ( 70 tests) | TZ GH KE ZA PH\n",
      "ZA: 12.5% accuracy ( 80 tests) | ZA JM GB GH TZ\n",
      "PH: 11.2% accuracy ( 80 tests) | PH SG JM GB CA\n",
      "US:  7.8% accuracy (680 tests) | GB US PH JM CA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.16757575757575757\n",
      "Averaged Average tries: 8.148948539560752\n",
      "IE: 41.1% accuracy (180 tests) | IE GB JM PH CA\n",
      "NZ: 35.7% accuracy (140 tests) | NZ JM AU GB PH\n",
      "PK: 32.2% accuracy ( 90 tests) | PK IN BD HK LK\n",
      "HK: 31.4% accuracy ( 70 tests) | HK JM US NG IE\n",
      "AU: 28.8% accuracy (260 tests) | AU PH US NZ SG\n",
      "SG: 28.7% accuracy ( 80 tests) | SG JM PH CA GB\n",
      "CA: 17.8% accuracy (230 tests) | CA JM GB US PH\n",
      "IN: 15.9% accuracy (170 tests) | IN BD GB ZA AU\n",
      "GB: 15.6% accuracy (680 tests) | GB JM PH CA US\n",
      "KE: 14.3% accuracy ( 70 tests) | TZ KE ZA GH JM\n",
      "JM: 14.3% accuracy ( 70 tests) | JM HK ZA CA GB\n",
      "GH: 14.3% accuracy ( 70 tests) | GH ZA TZ PH JM\n",
      "NG: 14.3% accuracy ( 70 tests) | NG JM BD LK KE\n",
      "BD: 12.9% accuracy ( 70 tests) | PK BD KE CA NG\n",
      "PH: 10.0% accuracy ( 80 tests) | GB PH JM SG CA\n",
      "US:  5.7% accuracy (680 tests) | GB JM US CA PH\n",
      "TZ:  5.0% accuracy ( 60 tests) | ZA IE TZ KE PH\n",
      "MY:  4.3% accuracy ( 70 tests) | GB JM MY HK CA\n",
      "ZA:  3.8% accuracy ( 80 tests) | ZA JM GH GB US\n",
      "LK:  1.2% accuracy ( 80 tests) | GB IN JM HK LK\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Classifier with undersampling\n",
    "rf_model = RandomForestClassifier(random_state=3)\n",
    "average_performance(rf_model, X, undersampling=True)\n",
    "average_performance(rf_model, X_25, undersampling=True)\n",
    "average_performance(rf_model, X_50, undersampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.1696969696969697\n",
      "Averaged Average tries: 7.565531432193836\n",
      "JM: 52.9% accuracy ( 70 tests) | JM PH HK CA TZ\n",
      "HK: 38.6% accuracy ( 70 tests) | HK TZ JM US PH\n",
      "TZ: 38.3% accuracy ( 60 tests) | TZ JM KE CA US\n",
      "LK: 37.5% accuracy ( 80 tests) | LK JM TZ HK PH\n",
      "PH: 27.5% accuracy ( 80 tests) | PH JM TZ CA GB\n",
      "NG: 27.1% accuracy ( 70 tests) | NG TZ JM PH HK\n",
      "IN: 24.1% accuracy (170 tests) | IN JM PH US TZ\n",
      "SG: 23.8% accuracy ( 80 tests) | SG PH JM HK US\n",
      "CA: 18.3% accuracy (230 tests) | PH CA JM US GB\n",
      "US: 16.3% accuracy (680 tests) | US PH JM CA TZ\n",
      "GB: 14.9% accuracy (680 tests) | JM PH GB TZ US\n",
      "PK: 14.4% accuracy ( 90 tests) | PK JM TZ PH GB\n",
      "NZ: 13.6% accuracy (140 tests) | JM PH NZ TZ CA\n",
      "KE: 12.9% accuracy ( 70 tests) | TZ PH KE JM US\n",
      "BD: 12.9% accuracy ( 70 tests) | PH JM BD TZ CA\n",
      "GH: 11.4% accuracy ( 70 tests) | TZ JM PH GH IN\n",
      "IE:  7.2% accuracy (180 tests) | JM PH TZ HK GB\n",
      "ZA:  6.2% accuracy ( 80 tests) | JM TZ PH US HK\n",
      "AU:  3.8% accuracy (260 tests) | JM TZ PH CA US\n",
      "MY:  2.9% accuracy ( 70 tests) | JM CA US HK PH\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.1606060606060606\n",
      "Averaged Average tries: 7.625823258511877\n",
      "JM: 40.0% accuracy ( 70 tests) | JM SG US CA ZA\n",
      "HK: 28.6% accuracy ( 70 tests) | HK US JM PH CA\n",
      "SG: 27.5% accuracy ( 80 tests) | SG JM PH MY AU\n",
      "NG: 25.7% accuracy ( 70 tests) | NG JM GB US CA\n",
      "PK: 20.0% accuracy ( 90 tests) | PK JM AU US GB\n",
      "CA: 19.1% accuracy (230 tests) | CA US JM GB PH\n",
      "PH: 18.8% accuracy ( 80 tests) | PH CA JM GB US\n",
      "US: 18.4% accuracy (680 tests) | US JM CA GB PH\n",
      "LK: 17.5% accuracy ( 80 tests) | LK JM PH GB CA\n",
      "GB: 16.9% accuracy (680 tests) | GB JM US CA AU\n",
      "BD: 15.7% accuracy ( 70 tests) | BD JM PH GB CA\n",
      "GH: 14.3% accuracy ( 70 tests) | GH GB JM AU TZ\n",
      "AU: 10.8% accuracy (260 tests) | JM AU CA GB US\n",
      "IN: 10.0% accuracy (170 tests) | JM GB CA US AU\n",
      "KE: 10.0% accuracy ( 70 tests) | GB JM KE US PH\n",
      "MY: 10.0% accuracy ( 70 tests) | JM US MY GB CA\n",
      "NZ:  8.6% accuracy (140 tests) | JM CA GB PH AU\n",
      "TZ:  6.7% accuracy ( 60 tests) | GB CA JM PH US\n",
      "ZA:  6.2% accuracy ( 80 tests) | JM CA PH US ZA\n",
      "IE:  5.6% accuracy (180 tests) | JM GB CA PH US\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.1351515151515152\n",
      "Averaged Average tries: 8.480528529973862\n",
      "HK: 30.0% accuracy ( 70 tests) | HK SG IE AU IN\n",
      "PK: 25.6% accuracy ( 90 tests) | PK IN LK PH GB\n",
      "SG: 21.2% accuracy ( 80 tests) | SG MY HK LK JM\n",
      "NZ: 17.9% accuracy (140 tests) | NZ PH IN AU GB\n",
      "IE: 16.1% accuracy (180 tests) | IE JM HK CA ZA\n",
      "US: 15.7% accuracy (680 tests) | US CA JM IE GB\n",
      "CA: 13.5% accuracy (230 tests) | CA US JM IE HK\n",
      "GH: 12.9% accuracy ( 70 tests) | GH JM TZ ZA MY\n",
      "IN: 12.4% accuracy (170 tests) | IN GB PK CA JM\n",
      "GB: 12.2% accuracy (680 tests) | GB JM US IE CA\n",
      "TZ: 11.7% accuracy ( 60 tests) | TZ GH IE ZA SG\n",
      "NG: 11.4% accuracy ( 70 tests) | TZ JM NG GH GB\n",
      "PH: 10.0% accuracy ( 80 tests) | PH GH JM HK US\n",
      "KE: 10.0% accuracy ( 70 tests) | TZ GH ZA GB JM\n",
      "LK:  8.8% accuracy ( 80 tests) | JM NG GH IN SG\n",
      "ZA:  8.8% accuracy ( 80 tests) | IE CA JM ZA TZ\n",
      "MY:  8.6% accuracy ( 70 tests) | MY US HK GB JM\n",
      "AU:  8.5% accuracy (260 tests) | AU US JM GB HK\n",
      "JM:  5.7% accuracy ( 70 tests) | NZ ZA SG HK GH\n",
      "BD:  5.7% accuracy ( 70 tests) | MY PH CA JM KE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Multi-layer Perceptron Model with undersampling\n",
    "mlp_model = MLPClassifier(random_state=3)\n",
    "average_performance(mlp_model,X, undersampling=True)\n",
    "average_performance(mlp_model,X_25, undersampling=True)\n",
    "average_performance(mlp_model,X_50, undersampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.1296969696969697\n",
      "Averaged Average tries: 10.494141754806718\n",
      "GB: 30.7% accuracy (680 tests) | GB US AU CA IN\n",
      "US: 23.1% accuracy (680 tests) | GB US CA AU IN\n",
      "JM:  8.6% accuracy ( 70 tests) | US GB CA AU JM\n",
      "CA:  6.5% accuracy (230 tests) | GB US AU CA NZ\n",
      "IE:  6.1% accuracy (180 tests) | US GB AU IE CA\n",
      "IN:  5.3% accuracy (170 tests) | GB US CA AU IN\n",
      "BD:  4.3% accuracy ( 70 tests) | US GB AU CA IE\n",
      "AU:  4.2% accuracy (260 tests) | GB US CA AU IN\n",
      "ZA:  3.8% accuracy ( 80 tests) | GB US AU IE PK\n",
      "PK:  2.2% accuracy ( 90 tests) | GB US AU IN GH\n",
      "NG:  1.4% accuracy ( 70 tests) | US GB AU IE CA\n",
      "NZ:  0.7% accuracy (140 tests) | GB US AU IN CA\n",
      "KE:  0.0% accuracy ( 70 tests) | GB US AU CA IE\n",
      "HK:  0.0% accuracy ( 70 tests) | US GB CA IN IE\n",
      "MY:  0.0% accuracy ( 70 tests) | GB US AU IN CA\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB AU IE NZ\n",
      "SG:  0.0% accuracy ( 80 tests) | GB US CA HK AU\n",
      "TZ:  0.0% accuracy ( 60 tests) | US GB IN CA AU\n",
      "GH:  0.0% accuracy ( 70 tests) | US GB AU IE CA\n",
      "PH:  0.0% accuracy ( 80 tests) | GB US AU CA NG\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.13545454545454544\n",
      "Averaged Average tries: 10.453493195494476\n",
      "US: 30.7% accuracy (680 tests) | US GB CA AU IE\n",
      "GB: 24.7% accuracy (680 tests) | US GB CA AU NZ\n",
      "AU:  8.5% accuracy (260 tests) | GB US AU CA IE\n",
      "IE:  5.6% accuracy (180 tests) | US GB CA AU IE\n",
      "CA:  4.8% accuracy (230 tests) | GB US AU CA IE\n",
      "NZ:  4.3% accuracy (140 tests) | GB US AU CA IE\n",
      "IN:  4.1% accuracy (170 tests) | GB US CA AU IE\n",
      "LK:  3.8% accuracy ( 80 tests) | GB US AU PK IN\n",
      "JM:  2.9% accuracy ( 70 tests) | US GB AU IE PH\n",
      "BD:  2.9% accuracy ( 70 tests) | US GB IE AU CA\n",
      "PH:  2.5% accuracy ( 80 tests) | US GB AU IN LK\n",
      "KE:  1.4% accuracy ( 70 tests) | GB US AU CA TZ\n",
      "MY:  1.4% accuracy ( 70 tests) | GB US AU IN CA\n",
      "NG:  1.4% accuracy ( 70 tests) | US GB NZ AU CA\n",
      "SG:  1.2% accuracy ( 80 tests) | GB US AU CA IE\n",
      "ZA:  1.2% accuracy ( 80 tests) | US GB AU NZ MY\n",
      "HK:  0.0% accuracy ( 70 tests) | GB US AU PK CA\n",
      "TZ:  0.0% accuracy ( 60 tests) | US GB AU CA IN\n",
      "GH:  0.0% accuracy ( 70 tests) | GB US CA AU IN\n",
      "PK:  0.0% accuracy ( 90 tests) | GB US CA AU IE\n",
      ". . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . \n",
      "Average Accuracy: 0.1290909090909091\n",
      "Averaged Average tries: 10.654153955060284\n",
      "GB: 26.5% accuracy (680 tests) | GB US AU CA NZ\n",
      "US: 25.6% accuracy (680 tests) | GB US AU CA IE\n",
      "IE:  8.9% accuracy (180 tests) | US GB AU IE CA\n",
      "AU:  6.9% accuracy (260 tests) | US GB CA AU IN\n",
      "BD:  5.7% accuracy ( 70 tests) | US GB CA IE JM\n",
      "CA:  5.7% accuracy (230 tests) | US GB AU IN CA\n",
      "PK:  5.6% accuracy ( 90 tests) | GB US AU IN CA\n",
      "IN:  4.1% accuracy (170 tests) | GB US AU NZ CA\n",
      "MY:  2.9% accuracy ( 70 tests) | GB US AU NZ IE\n",
      "NZ:  2.1% accuracy (140 tests) | US GB AU CA IE\n",
      "TZ:  1.7% accuracy ( 60 tests) | GB US AU BD PK\n",
      "HK:  1.4% accuracy ( 70 tests) | US AU IE GB CA\n",
      "GH:  1.4% accuracy ( 70 tests) | GB US AU CA NZ\n",
      "NG:  1.4% accuracy ( 70 tests) | US CA AU GB IN\n",
      "KE:  0.0% accuracy ( 70 tests) | GB US AU HK CA\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB CA AU PH\n",
      "SG:  0.0% accuracy ( 80 tests) | GB US CA IE NZ\n",
      "JM:  0.0% accuracy ( 70 tests) | GB US CA AU HK\n",
      "ZA:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      "PH:  0.0% accuracy ( 80 tests) | GB US NZ AU SG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression model with scrambling\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "average_performance(model, X, scrambling=True)\n",
    "average_performance(model, X_25, scrambling=True)\n",
    "average_performance(model, X_50, scrambling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.21454545454545454\n",
      "Averaged Average tries: 10.507599990943978\n",
      "US: 57.9% accuracy (680 tests) | US GB AU CA IE\n",
      "GB: 45.7% accuracy (680 tests) | US GB AU CA IE\n",
      "CA:  1.3% accuracy (230 tests) | US GB AU CA IE\n",
      "KE:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "HK:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "MY:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      "SG:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      "JM:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "TZ:  0.0% accuracy ( 60 tests) | US GB AU CA IE\n",
      "IE:  0.0% accuracy (180 tests) | US GB AU CA IN\n",
      "GH:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "IN:  0.0% accuracy (170 tests) | US GB AU CA IN\n",
      "NZ:  0.0% accuracy (140 tests) | US GB AU CA IE\n",
      "ZA:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      "PK:  0.0% accuracy ( 90 tests) | US GB AU CA IN\n",
      "BD:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "NG:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "AU:  0.0% accuracy (260 tests) | US GB AU CA IE\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.20424242424242425\n",
      "Averaged Average tries: 10.4144125453972\n",
      "US: 54.4% accuracy (680 tests) | US GB AU CA IE\n",
      "GB: 44.7% accuracy (680 tests) | US GB AU CA IE\n",
      "CA:  0.0% accuracy (230 tests) | US GB AU CA IE\n",
      "KE:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "HK:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "MY:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      "SG:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      "JM:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "TZ:  0.0% accuracy ( 60 tests) | US GB AU CA IE\n",
      "IE:  0.0% accuracy (180 tests) | US GB AU CA IN\n",
      "GH:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "IN:  0.0% accuracy (170 tests) | US GB AU CA IE\n",
      "NZ:  0.0% accuracy (140 tests) | US GB AU CA IE\n",
      "ZA:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      "PK:  0.0% accuracy ( 90 tests) | US GB AU CA IN\n",
      "BD:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "NG:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "AU:  0.0% accuracy (260 tests) | US GB AU CA IE\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.20606060606060606\n",
      "Averaged Average tries: 10.390874918808104\n",
      "US: 57.6% accuracy (680 tests) | US GB AU CA IE\n",
      "GB: 41.3% accuracy (680 tests) | US GB AU CA IE\n",
      "KE:  8.6% accuracy ( 70 tests) | US GB KE AU CA\n",
      "AU:  0.4% accuracy (260 tests) | US GB AU CA IN\n",
      "CA:  0.0% accuracy (230 tests) | US GB AU CA IE\n",
      "HK:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "MY:  0.0% accuracy ( 70 tests) | US GB CA AU IN\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      "SG:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      "JM:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "TZ:  0.0% accuracy ( 60 tests) | US GB AU CA IN\n",
      "IE:  0.0% accuracy (180 tests) | US GB AU CA IN\n",
      "GH:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "IN:  0.0% accuracy (170 tests) | US GB AU CA IN\n",
      "NZ:  0.0% accuracy (140 tests) | US GB CA AU IE\n",
      "ZA:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      "PK:  0.0% accuracy ( 90 tests) | US GB AU CA IE\n",
      "BD:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "NG:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Classifier with scrambled labels\n",
    "rf_model = RandomForestClassifier(random_state=3, class_weight='balanced')\n",
    "average_performance(rf_model, X, scrambling=True)\n",
    "average_performance(rf_model, X_25, scrambling=True)\n",
    "average_performance(rf_model, X_50, scrambling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.15969696969696973\n",
      "Averaged Average tries: 10.19422930348282\n",
      "US: 34.7% accuracy (680 tests) | GB US AU CA IN\n",
      "GB: 34.3% accuracy (680 tests) | US GB AU CA IN\n",
      "AU:  9.6% accuracy (260 tests) | US GB AU CA IN\n",
      "CA:  7.0% accuracy (230 tests) | US GB AU CA IN\n",
      "NZ:  3.6% accuracy (140 tests) | US GB AU CA IN\n",
      "IN:  2.9% accuracy (170 tests) | US GB AU CA IN\n",
      "IE:  1.7% accuracy (180 tests) | US GB AU CA IN\n",
      "HK:  1.4% accuracy ( 70 tests) | US GB AU PH IE\n",
      "JM:  1.4% accuracy ( 70 tests) | GB US AU CA LK\n",
      "PH:  1.2% accuracy ( 80 tests) | GB US AU CA PH\n",
      "PK:  1.1% accuracy ( 90 tests) | US GB AU CA HK\n",
      "KE:  0.0% accuracy ( 70 tests) | GB US AU CA IN\n",
      "MY:  0.0% accuracy ( 70 tests) | GB US AU CA IN\n",
      "LK:  0.0% accuracy ( 80 tests) | US GB AU MY CA\n",
      "SG:  0.0% accuracy ( 80 tests) | US GB AU CA IE\n",
      "TZ:  0.0% accuracy ( 60 tests) | GB US AU CA IE\n",
      "GH:  0.0% accuracy ( 70 tests) | GB US AU CA IN\n",
      "ZA:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n",
      "BD:  0.0% accuracy ( 70 tests) | US GB AU CA NZ\n",
      "NG:  0.0% accuracy ( 70 tests) | GB US AU IN JM\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.17212121212121212\n",
      "Averaged Average tries: 10.432632448185517\n",
      "US: 38.8% accuracy (680 tests) | GB US AU CA IE\n",
      "GB: 35.4% accuracy (680 tests) | GB US AU CA IE\n",
      "AU: 11.5% accuracy (260 tests) | US GB AU CA IN\n",
      "CA:  7.4% accuracy (230 tests) | GB US AU CA IE\n",
      "IE:  3.3% accuracy (180 tests) | US GB AU CA IE\n",
      "BD:  2.9% accuracy ( 70 tests) | GB US CA NZ NG\n",
      "ZA:  2.5% accuracy ( 80 tests) | US GB CA AU IN\n",
      "NZ:  2.1% accuracy (140 tests) | GB US AU CA IE\n",
      "NG:  1.4% accuracy ( 70 tests) | US GB AU CA NZ\n",
      "IN:  1.2% accuracy (170 tests) | US GB AU CA IN\n",
      "KE:  0.0% accuracy ( 70 tests) | GB US CA IN ZA\n",
      "HK:  0.0% accuracy ( 70 tests) | GB US IE CA AU\n",
      "MY:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "LK:  0.0% accuracy ( 80 tests) | GB US AU CA IN\n",
      "SG:  0.0% accuracy ( 80 tests) | GB US AU CA IE\n",
      "JM:  0.0% accuracy ( 70 tests) | GB US CA AU IN\n",
      "TZ:  0.0% accuracy ( 60 tests) | GB US IN AU CA\n",
      "GH:  0.0% accuracy ( 70 tests) | GB US IN AU NZ\n",
      "PK:  0.0% accuracy ( 90 tests) | GB US CA AU IN\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB AU IN CA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.14424242424242423\n",
      "Averaged Average tries: 10.215542664390172\n",
      "GB: 33.1% accuracy (680 tests) | US GB AU CA IN\n",
      "US: 29.6% accuracy (680 tests) | GB US AU CA IE\n",
      "AU:  7.3% accuracy (260 tests) | US GB AU IE CA\n",
      "CA:  4.3% accuracy (230 tests) | US GB AU IN IE\n",
      "IN:  4.1% accuracy (170 tests) | US GB AU IN NZ\n",
      "IE:  3.9% accuracy (180 tests) | US GB AU CA IN\n",
      "BD:  2.9% accuracy ( 70 tests) | US GB AU IE BD\n",
      "LK:  2.5% accuracy ( 80 tests) | US GB AU IN CA\n",
      "TZ:  1.7% accuracy ( 60 tests) | US GB AU JM ZA\n",
      "NZ:  1.4% accuracy (140 tests) | US GB AU CA IE\n",
      "KE:  0.0% accuracy ( 70 tests) | GB US CA PK AU\n",
      "HK:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "MY:  0.0% accuracy ( 70 tests) | US GB AU CA IE\n",
      "SG:  0.0% accuracy ( 80 tests) | GB US IN CA AU\n",
      "JM:  0.0% accuracy ( 70 tests) | US GB AU CA IN\n",
      "GH:  0.0% accuracy ( 70 tests) | GB US IE IN CA\n",
      "ZA:  0.0% accuracy ( 80 tests) | US GB AU IN IE\n",
      "PK:  0.0% accuracy ( 90 tests) | US GB AU IE CA\n",
      "NG:  0.0% accuracy ( 70 tests) | US GB AU IE CA\n",
      "PH:  0.0% accuracy ( 80 tests) | US GB AU CA IN\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Multi-layer Perceptron Model with scrambling\n",
    "mlp_model = MLPClassifier(random_state=3)\n",
    "average_performance(mlp_model,X, scrambling=True)\n",
    "average_performance(mlp_model,X_25, scrambling=True)\n",
    "average_performance(mlp_model,X_50, scrambling=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
