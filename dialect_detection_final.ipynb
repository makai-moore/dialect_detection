{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_dict = {}\n",
    "id_dict = {}\n",
    "word_count_dict = {}\n",
    "country_set = set()\n",
    "\n",
    "# pulls text IDs, country codes, document types, and word counts from the excel sheet,\n",
    "# using it to divide the documents into a dictionary by ID\n",
    "sources_df = pd.read_excel(\"./text/sampleSources.xlsx\", sheet_name=\"texts\")\n",
    "for text_id, (country_code, doc_type), word_count in [(l[0], tuple(l[1].split()), l[2]) for l in sources_df[[\"textID\", \"country|genre\", \"# words\"]].values.tolist()]:\n",
    "    with open(f\"./text/w_{country_code.lower()}_{doc_type.lower()}.txt\", 'r',\n",
    "              encoding=\"utf-8\") as file:\n",
    "        # add each text_id to id_dict\n",
    "        if f\"{country_code}_{doc_type}\" not in id_dict:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"] = [text_id]\n",
    "        else:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"].append(text_id)\n",
    "        # makes country code set\n",
    "        country_set.add(country_code)\n",
    "        # finds correct text_id and adds every line in the document to the dictionary\n",
    "        IS_DOC = False\n",
    "        lines = file.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith(f\"##{text_id}\"):\n",
    "                IS_DOC = True\n",
    "            elif line.strip().startswith(\"##\"):\n",
    "                IS_DOC = False\n",
    "            if IS_DOC:\n",
    "                if text_id not in doc_dict:\n",
    "                    doc_dict[text_id] = [w.lower() for w in line.split()]\n",
    "                else:\n",
    "                    doc_dict[text_id] += [w.lower() for w in line.split()]\n",
    "        # adds word count to dictionary\n",
    "        word_count_dict[text_id] = word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "# make a counter for every word in the corpus\n",
    "vocab = Counter({})\n",
    "vocab['<UNK>'] = 0\n",
    "for doc in doc_dict.values():\n",
    "    for word in doc:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "\n",
    "# make a dictionary of sets for every country and record every word used by each country\n",
    "# also make a word count for every country\n",
    "vocab_sets = {country_code:set() for country_code in country_set}\n",
    "country_word_counts = Counter({country_code:0 for country_code in country_set})\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        for word in doc_dict[text_id]:\n",
    "            vocab_sets[country_code].add(word)\n",
    "        country_word_counts[country_code] += word_count_dict[text_id]\n",
    "\n",
    "# make new vocabulary sets, removing words that appear in less than\n",
    "# 12.5%, 25%, 37.5%, and 50% of the countries datasets respectively\n",
    "vocab_25 = vocab.copy()\n",
    "vocab_50 = vocab.copy()\n",
    "for word in vocab:\n",
    "    COUNTRY_COUNT = 0\n",
    "    for country_code in country_set:\n",
    "        if word in vocab_sets[country_code]:\n",
    "            COUNTRY_COUNT+=1\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.25:\n",
    "        del vocab_25[word]\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.5:\n",
    "        del vocab_50[word]\n",
    "\n",
    "# Replace any words that appear in less than 25% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_25 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_25.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_25:\n",
    "            doc_dict_25[text_id][i] = '<UNK>'\n",
    "            vocab_25['<UNK>'] += 1\n",
    "\n",
    "# Replace any words that appear in less than 50% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_50 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_50.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_50:\n",
    "            doc_dict_50[text_id][i] = '<UNK>'\n",
    "            vocab_50['<UNK>'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# make a dataframe of one-hot representations of each text in each version of the dataset with their country labels\n",
    "text_ids = []\n",
    "texts = []\n",
    "texts_25 = []\n",
    "texts_50 = []\n",
    "country_labels = []\n",
    "\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        text_ids.append(text_ids)\n",
    "        texts.append(\" \".join(doc_dict[text_id]))\n",
    "        texts_25.append(\" \".join(doc_dict_25[text_id]))\n",
    "        texts_50.append(\" \".join(doc_dict_50[text_id]))\n",
    "        country_labels.append(country_code)\n",
    "\n",
    "data = {\n",
    "    'text_id': text_ids,\n",
    "    'texts': texts,\n",
    "    'texts_25': texts_25,\n",
    "    'texts_50': texts_50,\n",
    "    'country_labels': country_labels\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['texts'])\n",
    "X_25 = vectorizer.fit_transform(df['texts_25'])\n",
    "X_50 = vectorizer.fit_transform(df['texts_50'])\n",
    "y = df['country_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_breakdown(model, X_test, y_test):\n",
    "    # makes a dictionary of probability Counters for every country label for each country's documents\n",
    "    most_probable_country = {c:Counter({c:0 for c in country_set}) for c in country_set}\n",
    "    for test_num, probabilities in enumerate(model.predict_proba(X_test)):\n",
    "        for i, probability in enumerate(probabilities):\n",
    "            most_probable_country[y_test.tolist()[test_num]][model.classes_[i]] += probability  \n",
    "\n",
    "    return most_probable_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tries(model, X_test, y_test, print_output=False):\n",
    "    \"\"\"\n",
    "    Takes the model and testing data.\n",
    "    Returns average tries needed to return the right label,\n",
    "    average tries per country, and number of tests per country.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Matches each country label to its probability in a dataframe\n",
    "    df = pd.DataFrame(model.predict_proba(X_test).tolist(), columns=model.classes_.tolist())\n",
    "\n",
    "    # Sorts each probability distribution for highest probability\n",
    "    # and records the number of iterations needed to get to the right label\n",
    "    country_try_count = {c:0 for c in country_set}\n",
    "    country_test_count = Counter(y_test)\n",
    "    for i in range(len(df)):\n",
    "        for try_count, (country_code, _) in enumerate(sorted(df.iloc[i].to_dict().items(), key=lambda item: item[1], reverse=True)):\n",
    "            if country_code == y_test.tolist()[i]:\n",
    "                country_try_count[country_code] += try_count+1\n",
    "                break\n",
    "    \n",
    "    # Averages the country try count by number of tests\n",
    "    country_try_count = {country:country_try_count[country]/country_test_count[country] for country in country_try_count}\n",
    "    # Computes overal average try count\n",
    "    avg_tries = sum(country_try_count.values())/len(country_try_count)\n",
    "    \n",
    "    # Either returns or prints the results\n",
    "    if print_output:\n",
    "        for country, try_count in sorted(country_try_count.items(), key=lambda item: item[1]):\n",
    "            print(country, f\"{try_count:.1f} tries\", f\"({country_test_count[country]} tests)\")\n",
    "        print(\"Average number of tries:\", avg_tries)\n",
    "    else:\n",
    "        return avg_tries, country_try_count, country_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def average_performance(model, X_dataset, random_states=10):\n",
    "    \"\"\"\n",
    "    Takes the model, dataset, and number of random test splits to test.\n",
    "    Prints average accuracy and tries between all test splits of the model.\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    tries = []\n",
    "    avg_country_try_count = {c:0 for c in country_set}\n",
    "    total_country_test_count = {c:0 for c in country_set}\n",
    "    avg_most_probable_country = {c:Counter({c:0 for c in country_set}) for c in country_set}\n",
    "\n",
    "    # trains models on the specified number of random splits\n",
    "    for r in range(random_states):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_dataset, y, test_size=0.2, random_state=r)\n",
    "        model.fit(X_train, y_train)\n",
    "        # computes accuracies\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        # computes overall and country try counts\n",
    "        avg_tries, country_try_count, country_test_count = average_tries(model, X_test, y_test)\n",
    "        tries.append(avg_tries)\n",
    "        # computes similar countries\n",
    "        most_probable_country = probability_breakdown(model, X_test, y_test)\n",
    "        for country in country_try_count:\n",
    "            avg_country_try_count[country] += country_try_count[country]\n",
    "            total_country_test_count[country] += country_test_count[country]\n",
    "            avg_most_probable_country[country] += most_probable_country[country]\n",
    "        print(\".\",end=\" \")\n",
    "    print()\n",
    "    \n",
    "    print(\"Average Accuracy:\", np.mean(accuracies))\n",
    "    print(\"Averaged Average tries:\", np.mean(tries))\n",
    "    # Sorts country try counts and prints them in order\n",
    "    avg_country_try_count = {country:avg_country_try_count[country]/(random_states) for country in avg_country_try_count}\n",
    "    for country, try_count in sorted(avg_country_try_count.items(), key=lambda item: item[1]):\n",
    "        most_similar_five = \" \".join([country for country, _ in avg_most_probable_country[country].most_common(5)])\n",
    "        print(f\"{country}: {try_count:4.1f} tries\", f\"({total_country_test_count[country]:3d} tests) | {most_similar_five}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.3115151515151516\n",
      "Averaged Average tries: 7.4150612910582625\n",
      "GB:  2.5 tries (663 tests) | GB US AU CA IN\n",
      "US:  2.7 tries (685 tests) | US GB AU CA NZ\n",
      "AU:  4.4 tries (272 tests) | AU GB US CA NZ\n",
      "IE:  5.1 tries (185 tests) | IE GB US PH CA\n",
      "CA:  5.2 tries (226 tests) | US GB CA AU IE\n",
      "NZ:  6.0 tries (121 tests) | NZ GB US AU PH\n",
      "GH:  6.3 tries ( 64 tests) | GH GB US AU CA\n",
      "IN:  6.3 tries (186 tests) | GB US IN CA NZ\n",
      "PK:  6.4 tries ( 92 tests) | PK US GB AU IN\n",
      "LK:  6.9 tries ( 82 tests) | LK GB US IN AU\n",
      "KE:  7.4 tries ( 81 tests) | KE US GB JM CA\n",
      "BD:  8.2 tries ( 64 tests) | BD GB US IE IN\n",
      "ZA:  9.4 tries ( 81 tests) | US GB CA AU ZA\n",
      "HK:  9.6 tries ( 74 tests) | US HK GB MY IN\n",
      "TZ:  9.7 tries ( 54 tests) | GB US TZ IN IE\n",
      "NG:  9.8 tries ( 77 tests) | GB US NG AU IN\n",
      "SG:  9.9 tries ( 75 tests) | US GB SG IN MY\n",
      "MY: 10.0 tries ( 76 tests) | GB US CA MY JM\n",
      "JM: 11.3 tries ( 67 tests) | GB US IE JM AU\n",
      "PH: 11.3 tries ( 75 tests) | GB US AU CA KE\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.2975757575757576\n",
      "Averaged Average tries: 7.531030783862482\n",
      "GB:  2.7 tries (663 tests) | GB US AU CA IN\n",
      "US:  2.8 tries (685 tests) | US GB AU CA IN\n",
      "AU:  4.7 tries (272 tests) | AU GB US CA NZ\n",
      "IE:  5.4 tries (185 tests) | IE GB US CA AU\n",
      "CA:  5.5 tries (226 tests) | US GB CA AU IE\n",
      "NZ:  5.9 tries (121 tests) | NZ GB US AU IN\n",
      "IN:  6.3 tries (186 tests) | GB US IN CA AU\n",
      "PK:  6.4 tries ( 92 tests) | PK US GB AU IN\n",
      "GH:  6.8 tries ( 64 tests) | GH GB US AU CA\n",
      "LK:  7.3 tries ( 82 tests) | LK GB US IN AU\n",
      "KE:  7.5 tries ( 81 tests) | KE US GB CA JM\n",
      "BD:  7.9 tries ( 64 tests) | BD GB US IE IN\n",
      "MY:  9.4 tries ( 76 tests) | US GB MY CA AU\n",
      "HK:  9.6 tries ( 74 tests) | US HK GB IN MY\n",
      "ZA:  9.6 tries ( 81 tests) | US CA GB AU ZA\n",
      "SG:  9.8 tries ( 75 tests) | GB US SG AU IN\n",
      "NG: 10.0 tries ( 77 tests) | US GB NG AU IN\n",
      "TZ: 10.0 tries ( 54 tests) | GB US TZ IN KE\n",
      "PH: 10.9 tries ( 75 tests) | GB US AU CA MY\n",
      "JM: 12.3 tries ( 67 tests) | GB US IE AU CA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.27303030303030307\n",
      "Averaged Average tries: 7.968801062460178\n",
      "GB:  2.8 tries (663 tests) | GB US AU CA IN\n",
      "US:  3.0 tries (685 tests) | US GB AU CA NZ\n",
      "AU:  4.8 tries (272 tests) | AU GB US CA NZ\n",
      "CA:  5.8 tries (226 tests) | US GB CA IN AU\n",
      "IE:  5.9 tries (185 tests) | IE GB US CA AU\n",
      "PK:  6.0 tries ( 92 tests) | US GB PK IN AU\n",
      "NZ:  6.0 tries (121 tests) | NZ GB US AU IN\n",
      "IN:  6.3 tries (186 tests) | GB US IN CA AU\n",
      "GH:  7.2 tries ( 64 tests) | GH GB US KE IN\n",
      "KE:  8.0 tries ( 81 tests) | KE US GB JM CA\n",
      "HK:  9.5 tries ( 74 tests) | US HK IN GB MY\n",
      "SG:  9.6 tries ( 75 tests) | GB US SG IN MY\n",
      "BD:  9.7 tries ( 64 tests) | IE GB US KE CA\n",
      "ZA:  9.9 tries ( 81 tests) | US GB CA AU ZA\n",
      "TZ:  9.9 tries ( 54 tests) | GB US TZ IN AU\n",
      "LK: 10.0 tries ( 82 tests) | GB US IE AU IN\n",
      "MY: 10.0 tries ( 76 tests) | GB US LK CA AU\n",
      "NG: 11.0 tries ( 77 tests) | GB US AU NG GH\n",
      "PH: 11.3 tries ( 75 tests) | GB US AU CA MY\n",
      "JM: 12.4 tries ( 67 tests) | GB US IE AU GH\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression model with class weights balanced\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "average_performance(model, X)\n",
    "average_performance(model, X_25)\n",
    "average_performance(model, X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.3242424242424242\n",
      "Averaged Average tries: 6.511404179132822\n",
      "GB:  1.4 tries (663 tests) | GB US CA AU IE\n",
      "US:  1.6 tries (685 tests) | US GB CA AU IN\n",
      "AU:  3.3 tries (272 tests) | GB US AU CA NZ\n",
      "CA:  3.7 tries (226 tests) | US GB CA AU IE\n",
      "IE:  3.7 tries (185 tests) | GB US IE AU CA\n",
      "IN:  4.9 tries (186 tests) | GB US IN AU CA\n",
      "LK:  5.1 tries ( 82 tests) | GB US LK IN CA\n",
      "NZ:  5.2 tries (121 tests) | GB US NZ AU CA\n",
      "GH:  6.4 tries ( 64 tests) | GB US GH AU CA\n",
      "NG:  6.7 tries ( 77 tests) | GB US NG CA AU\n",
      "BD:  6.9 tries ( 64 tests) | GB US BD IN CA\n",
      "PK:  7.1 tries ( 92 tests) | GB US PK AU CA\n",
      "SG:  8.3 tries ( 75 tests) | GB US AU SG CA\n",
      "JM:  8.6 tries ( 67 tests) | GB US JM CA AU\n",
      "KE:  8.6 tries ( 81 tests) | GB US AU CA KE\n",
      "HK:  9.0 tries ( 74 tests) | GB US AU CA HK\n",
      "TZ:  9.1 tries ( 54 tests) | GB US AU CA TZ\n",
      "PH: 10.0 tries ( 75 tests) | GB US AU CA PH\n",
      "MY: 10.1 tries ( 76 tests) | GB US AU CA MY\n",
      "ZA: 10.5 tries ( 81 tests) | GB US AU CA ZA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.34333333333333327\n",
      "Averaged Average tries: 6.792252907252715\n",
      "GB:  1.5 tries (663 tests) | GB US CA AU IE\n",
      "US:  1.5 tries (685 tests) | US GB CA AU IN\n",
      "AU:  3.3 tries (272 tests) | GB US AU CA NZ\n",
      "IE:  3.8 tries (185 tests) | IE GB US AU CA\n",
      "CA:  3.9 tries (226 tests) | GB US CA AU IE\n",
      "NZ:  5.3 tries (121 tests) | GB US NZ AU CA\n",
      "IN:  5.4 tries (186 tests) | GB US IN AU CA\n",
      "GH:  5.9 tries ( 64 tests) | GB US GH AU CA\n",
      "LK:  6.2 tries ( 82 tests) | GB US LK IN AU\n",
      "BD:  7.1 tries ( 64 tests) | GB US BD IN AU\n",
      "PK:  7.4 tries ( 92 tests) | GB US PK CA AU\n",
      "KE:  7.9 tries ( 81 tests) | GB US AU CA KE\n",
      "NG:  8.1 tries ( 77 tests) | GB US NG AU CA\n",
      "SG:  8.2 tries ( 75 tests) | GB US SG AU CA\n",
      "HK:  8.5 tries ( 74 tests) | GB US HK CA AU\n",
      "JM: 10.0 tries ( 67 tests) | GB US IE AU CA\n",
      "MY: 10.1 tries ( 76 tests) | GB US AU CA MY\n",
      "TZ: 10.2 tries ( 54 tests) | GB US AU CA TZ\n",
      "PH: 10.5 tries ( 75 tests) | US GB CA AU PH\n",
      "ZA: 10.9 tries ( 81 tests) | GB US AU CA ZA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.283030303030303\n",
      "Averaged Average tries: 8.112228219670572\n",
      "GB:  1.4 tries (663 tests) | GB US AU CA IE\n",
      "US:  1.6 tries (685 tests) | GB US CA AU IN\n",
      "AU:  3.4 tries (272 tests) | GB US AU CA NZ\n",
      "CA:  4.3 tries (226 tests) | GB US CA AU IE\n",
      "IE:  4.6 tries (185 tests) | GB US IE AU CA\n",
      "IN:  5.6 tries (186 tests) | GB US IN AU CA\n",
      "NZ:  6.0 tries (121 tests) | GB US NZ AU CA\n",
      "PK:  7.8 tries ( 92 tests) | GB US PK CA AU\n",
      "SG:  8.0 tries ( 75 tests) | GB US AU SG CA\n",
      "GH:  8.4 tries ( 64 tests) | GB US AU GH ZA\n",
      "HK:  9.2 tries ( 74 tests) | US GB HK AU CA\n",
      "KE:  9.5 tries ( 81 tests) | GB US AU CA IE\n",
      "BD: 10.6 tries ( 64 tests) | GB US IN AU CA\n",
      "LK: 11.1 tries ( 82 tests) | GB US CA AU IN\n",
      "NG: 11.3 tries ( 77 tests) | GB US AU CA IN\n",
      "JM: 11.3 tries ( 67 tests) | GB US CA IE AU\n",
      "ZA: 11.7 tries ( 81 tests) | GB US CA AU IE\n",
      "MY: 11.9 tries ( 76 tests) | GB US AU CA IE\n",
      "PH: 12.0 tries ( 75 tests) | GB US CA AU IE\n",
      "TZ: 12.4 tries ( 54 tests) | GB US AU IE CA\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Classifier with class weights balanced\n",
    "rf_model = RandomForestClassifier(random_state=3, class_weight='balanced')\n",
    "average_performance(rf_model, X)\n",
    "average_performance(rf_model, X_25)\n",
    "average_performance(rf_model, X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.3251515151515152\n",
      "Averaged Average tries: 7.455500516530901\n",
      "GB:  2.0 tries (663 tests) | GB US CA AU IN\n",
      "US:  2.2 tries (685 tests) | US GB CA AU IN\n",
      "CA:  3.7 tries (226 tests) | US GB CA AU IN\n",
      "AU:  4.0 tries (272 tests) | GB US AU CA IE\n",
      "IE:  5.4 tries (185 tests) | GB US IE CA AU\n",
      "IN:  5.5 tries (186 tests) | GB US IN CA AU\n",
      "NZ:  6.2 tries (121 tests) | GB US NZ CA AU\n",
      "TZ:  6.6 tries ( 54 tests) | GB US AU CA TZ\n",
      "PK:  7.1 tries ( 92 tests) | US GB PK CA AU\n",
      "KE:  7.3 tries ( 81 tests) | US GB CA AU KE\n",
      "LK:  7.7 tries ( 82 tests) | GB US LK AU CA\n",
      "HK:  8.0 tries ( 74 tests) | US GB HK CA AU\n",
      "PH:  8.4 tries ( 75 tests) | GB US CA PH AU\n",
      "JM:  8.6 tries ( 67 tests) | GB US CA JM NZ\n",
      "SG:  9.2 tries ( 75 tests) | GB US AU SG CA\n",
      "BD:  9.2 tries ( 64 tests) | GB US BD AU CA\n",
      "NG: 11.4 tries ( 77 tests) | GB US AU CA NG\n",
      "GH: 11.6 tries ( 64 tests) | GB US AU GH CA\n",
      "MY: 12.3 tries ( 76 tests) | US GB CA AU IN\n",
      "ZA: 12.9 tries ( 81 tests) | US CA GB AU JM\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.29424242424242425\n",
      "Averaged Average tries: 7.553699894419635\n",
      "US:  2.5 tries (685 tests) | US GB CA AU IN\n",
      "GB:  2.5 tries (663 tests) | GB US CA AU IN\n",
      "AU:  3.7 tries (272 tests) | GB US AU CA IE\n",
      "CA:  4.4 tries (226 tests) | US GB CA AU IN\n",
      "IE:  5.8 tries (185 tests) | US GB IE AU CA\n",
      "PK:  6.7 tries ( 92 tests) | GB US PK CA IN\n",
      "NG:  6.9 tries ( 77 tests) | US GB AU NG CA\n",
      "LK:  7.0 tries ( 82 tests) | GB US LK AU CA\n",
      "NZ:  7.0 tries (121 tests) | GB US NZ AU CA\n",
      "IN:  7.3 tries (186 tests) | US GB CA IN AU\n",
      "HK:  8.5 tries ( 74 tests) | US CA GB HK AU\n",
      "BD:  8.6 tries ( 64 tests) | US GB BD IN CA\n",
      "JM:  9.2 tries ( 67 tests) | GB US AU IN CA\n",
      "KE:  9.4 tries ( 81 tests) | US GB CA AU TZ\n",
      "MY:  9.4 tries ( 76 tests) | US GB AU MY CA\n",
      "TZ:  9.9 tries ( 54 tests) | GB US CA AU IE\n",
      "PH: 10.2 tries ( 75 tests) | US GB CA AU PH\n",
      "GH: 10.3 tries ( 64 tests) | US GB GH CA AU\n",
      "ZA: 10.5 tries ( 81 tests) | US GB CA AU JM\n",
      "SG: 11.1 tries ( 75 tests) | US GB AU SG CA\n",
      ". . . . . . . . . . \n",
      "Average Accuracy: 0.29000000000000004\n",
      "Averaged Average tries: 8.372042301918263\n",
      "US:  2.8 tries (685 tests) | US GB CA AU IE\n",
      "GB:  3.1 tries (663 tests) | GB US CA AU IE\n",
      "AU:  5.0 tries (272 tests) | GB US AU CA IE\n",
      "CA:  5.0 tries (226 tests) | GB US CA AU IE\n",
      "IE:  5.5 tries (185 tests) | US IE GB CA AU\n",
      "PK:  5.8 tries ( 92 tests) | US PK GB IN CA\n",
      "NZ:  5.9 tries (121 tests) | GB NZ US AU IN\n",
      "GH:  7.9 tries ( 64 tests) | US GB GH AU IE\n",
      "IN:  7.9 tries (186 tests) | GB US IN CA AU\n",
      "HK:  8.7 tries ( 74 tests) | US GB HK AU IE\n",
      "SG:  9.6 tries ( 75 tests) | US AU SG GB CA\n",
      "TZ: 10.3 tries ( 54 tests) | US GB IN SG ZA\n",
      "NG: 10.3 tries ( 77 tests) | US GB AU CA IN\n",
      "ZA: 10.9 tries ( 81 tests) | GB US AU CA ZA\n",
      "JM: 11.0 tries ( 67 tests) | GB US AU IN CA\n",
      "PH: 11.0 tries ( 75 tests) | US GB AU CA PH\n",
      "MY: 11.0 tries ( 76 tests) | US GB CA AU JM\n",
      "BD: 11.1 tries ( 64 tests) | GB US IE IN BD\n",
      "KE: 12.3 tries ( 81 tests) | US GB CA AU ZA\n",
      "LK: 12.5 tries ( 82 tests) | GB US AU CA IN\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Multi-layer Perceptron Model\n",
    "mlp_model = MLPClassifier(random_state=3)\n",
    "average_performance(mlp_model,X)\n",
    "average_performance(mlp_model,X_25)\n",
    "average_performance(mlp_model,X_50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
