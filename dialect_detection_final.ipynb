{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc_dict = {}\n",
    "id_dict = {}\n",
    "word_count_dict = {}\n",
    "country_set = set()\n",
    "\n",
    "# pulls text IDs, country codes, document types, and word counts from the excel sheet,\n",
    "# using it to divide the documents into a dictionary by ID\n",
    "sources_df = pd.read_excel(\"./text/sampleSources.xlsx\", sheet_name=\"texts\")\n",
    "for text_id, (country_code, doc_type), word_count in [(l[0], tuple(l[1].split()), l[2]) for l in sources_df[[\"textID\", \"country|genre\", \"# words\"]].values.tolist()]:\n",
    "    with open(f\"./text/w_{country_code.lower()}_{doc_type.lower()}.txt\", 'r',\n",
    "              encoding=\"utf-8\") as file:\n",
    "        # add each text_id to id_dict\n",
    "        if f\"{country_code}_{doc_type}\" not in id_dict:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"] = [text_id]\n",
    "        else:\n",
    "            id_dict[f\"{country_code}_{doc_type}\"].append(text_id)\n",
    "        # makes country code set\n",
    "        country_set.add(country_code)\n",
    "        # finds correct text_id and adds every line in the document to the dictionary\n",
    "        IS_DOC = False\n",
    "        lines = file.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith(f\"##{text_id}\"):\n",
    "                IS_DOC = True\n",
    "            elif line.strip().startswith(\"##\"):\n",
    "                IS_DOC = False\n",
    "            if IS_DOC:\n",
    "                if text_id not in doc_dict:\n",
    "                    doc_dict[text_id] = [w.lower() for w in line.split()]\n",
    "                else:\n",
    "                    doc_dict[text_id] += [w.lower() for w in line.split()]\n",
    "        # adds word count to dictionary\n",
    "        word_count_dict[text_id] = word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "# make a counter for every word in the corpus\n",
    "vocab = Counter({})\n",
    "vocab['<UNK>'] = 0\n",
    "for doc in doc_dict.values():\n",
    "    for word in doc:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1\n",
    "\n",
    "# make a dictionary of sets for every country and record every word used by each country\n",
    "# also make a word count for every country\n",
    "vocab_sets = {country_code:set() for country_code in country_set}\n",
    "country_word_counts = Counter({country_code:0 for country_code in country_set})\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        for word in doc_dict[text_id]:\n",
    "            vocab_sets[country_code].add(word)\n",
    "        country_word_counts[country_code] += word_count_dict[text_id]\n",
    "\n",
    "# make new vocabulary sets, removing words that appear in less than\n",
    "# 12.5%, 25%, 37.5%, and 50% of the countries datasets respectively\n",
    "vocab_25 = vocab.copy()\n",
    "vocab_50 = vocab.copy()\n",
    "for word in vocab:\n",
    "    COUNTRY_COUNT = 0\n",
    "    for country_code in country_set:\n",
    "        if word in vocab_sets[country_code]:\n",
    "            COUNTRY_COUNT+=1\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.25:\n",
    "        del vocab_25[word]\n",
    "    if COUNTRY_COUNT / len(country_set) < 0.5:\n",
    "        del vocab_50[word]\n",
    "\n",
    "# Replace any words that appear in less than 25% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_25 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_25.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_25:\n",
    "            doc_dict_25[text_id][i] = '<UNK>'\n",
    "            vocab_25['<UNK>'] += 1\n",
    "\n",
    "# Replace any words that appear in less than 50% of the countries’ datasets with the <UNK> token\n",
    "doc_dict_50 = copy.deepcopy(doc_dict)\n",
    "for text_id, doc in doc_dict_50.items():\n",
    "    for i, word in enumerate(doc):\n",
    "        if word not in vocab_50:\n",
    "            doc_dict_50[text_id][i] = '<UNK>'\n",
    "            vocab_50['<UNK>'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# make a dataframe of one-hot representations of each text in each version of the dataset with their country labels\n",
    "text_ids = []\n",
    "texts = []\n",
    "texts_25 = []\n",
    "texts_50 = []\n",
    "country_labels = []\n",
    "\n",
    "for country_code in country_set:\n",
    "    for text_id in id_dict[f\"{country_code}_B\"] + id_dict[f\"{country_code}_G\"]:\n",
    "        text_ids.append(text_ids)\n",
    "        texts.append(\" \".join(doc_dict[text_id]))\n",
    "        texts_25.append(\" \".join(doc_dict_25[text_id]))\n",
    "        texts_50.append(\" \".join(doc_dict_50[text_id]))\n",
    "        country_labels.append(country_code)\n",
    "\n",
    "data = {\n",
    "    'text_id': text_ids,\n",
    "    'texts': texts,\n",
    "    'texts_25': texts_25,\n",
    "    'texts_50': texts_50,\n",
    "    'country_labels': country_labels\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['texts'])\n",
    "X_25 = vectorizer.fit_transform(df['texts_25'])\n",
    "X_50 = vectorizer.fit_transform(df['texts_50'])\n",
    "y = df['country_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tries(model, X_test, y_test, print_output=False):\n",
    "    \"\"\"\n",
    "    Takes the model and testing data.\n",
    "    Returns average tries needed to return the right label,\n",
    "    average tries per country, and number of tests per country.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Matches each country label to its probability in a dataframe\n",
    "    df = pd.DataFrame(model.predict_proba(X_test).tolist(), columns=model.classes_.tolist())\n",
    "\n",
    "    # Sorts each probability distribution for highest probability\n",
    "    # and records the number of iterations needed to get to the right label\n",
    "    country_try_count = {c:0 for c in country_set}\n",
    "    country_test_count = Counter(y_test)\n",
    "    for i in range(len(df)):\n",
    "        for try_count, (country_code, _) in enumerate(sorted(df.iloc[i].to_dict().items(), key=lambda item: item[1], reverse=True)):\n",
    "            if country_code == y_test.tolist()[i]:\n",
    "                country_try_count[country_code] += try_count+1\n",
    "                break\n",
    "    \n",
    "    # Averages the country try count by number of tests\n",
    "    country_try_count = {country:country_try_count[country]/country_test_count[country] for country in country_try_count}\n",
    "    # Computes overal average try count\n",
    "    avg_tries = sum(country_try_count.values())/len(country_try_count)\n",
    "    \n",
    "    # Either returns or prints the results\n",
    "    if print_output:\n",
    "        for country, try_count in sorted(country_try_count.items(), key=lambda item: item[1]):\n",
    "            print(country, f\"{try_count:.1f} tries\", f\"({country_test_count[country]} tests)\")\n",
    "        print(\"Average number of tries:\", avg_tries)\n",
    "    else:\n",
    "        return avg_tries, country_try_count, country_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def average_performance(model, X_dataset, random_states=5):\n",
    "    \"\"\"\n",
    "    Takes the model, dataset, and number of random test splits to test.\n",
    "    Prints average accuracy and tries between all test splits of the model.\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    tries = []\n",
    "    avg_country_try_count = {c:0 for c in country_set}\n",
    "    total_country_test_count = {c:0 for c in country_set}\n",
    "\n",
    "    # trains models on the specified number of random splits\n",
    "    for r in range(random_states):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_dataset, y, test_size=0.2, random_state=r)\n",
    "        model.fit(X_train, y_train)\n",
    "        # computes accuracies\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        # computes overall and country try counts\n",
    "        avg_tries, country_try_count, country_test_count = average_tries(model, X_test, y_test)\n",
    "        tries.append(avg_tries)\n",
    "        for country in country_try_count:\n",
    "            avg_country_try_count[country] += country_try_count[country]\n",
    "            total_country_test_count[country] += country_test_count[country]\n",
    "        print(\".\",end=\" \")\n",
    "    print()\n",
    "    \n",
    "    print(\"Average Accuracy:\", np.mean(accuracies))\n",
    "    print(\"Averaged Average tries:\", np.mean(tries))\n",
    "    # Sorts country try counts and prints them in order\n",
    "    avg_country_try_count = {country:avg_country_try_count[country]/(random_states) for country in avg_country_try_count}\n",
    "    for country, try_count in sorted(avg_country_try_count.items(), key=lambda item: item[1]):\n",
    "        print(country, f\"{try_count:.1f} tries\", f\"({total_country_test_count[country]} tests)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . \n",
      "Average Accuracy: 0.28727272727272724\n",
      "Averaged Average tries: 7.286789866952094\n",
      "GB 2.8 tries (326 tests)\n",
      "US 3.1 tries (332 tests)\n",
      "IE 4.5 tries (82 tests)\n",
      "AU 5.0 tries (140 tests)\n",
      "CA 5.5 tries (120 tests)\n",
      "IN 5.6 tries (75 tests)\n",
      "BD 6.2 tries (38 tests)\n",
      "KE 6.4 tries (36 tests)\n",
      "NZ 6.4 tries (67 tests)\n",
      "PK 7.1 tries (55 tests)\n",
      "ZA 7.5 tries (35 tests)\n",
      "GH 8.0 tries (33 tests)\n",
      "JM 8.1 tries (33 tests)\n",
      "TZ 8.6 tries (41 tests)\n",
      "LK 9.2 tries (48 tests)\n",
      "NG 9.5 tries (37 tests)\n",
      "HK 9.7 tries (40 tests)\n",
      "SG 10.1 tries (37 tests)\n",
      "MY 10.9 tries (34 tests)\n",
      "PH 11.5 tries (41 tests)\n",
      ". . . . . \n",
      "Average Accuracy: 0.26181818181818184\n",
      "Averaged Average tries: 7.461764976630898\n",
      "GB 2.9 tries (326 tests)\n",
      "US 3.3 tries (332 tests)\n",
      "IE 4.9 tries (82 tests)\n",
      "AU 5.0 tries (140 tests)\n",
      "IN 5.5 tries (75 tests)\n",
      "BD 5.9 tries (38 tests)\n",
      "CA 6.0 tries (120 tests)\n",
      "NZ 6.4 tries (67 tests)\n",
      "KE 6.5 tries (36 tests)\n",
      "PK 7.3 tries (55 tests)\n",
      "GH 8.2 tries (33 tests)\n",
      "ZA 8.2 tries (35 tests)\n",
      "TZ 8.4 tries (41 tests)\n",
      "JM 9.5 tries (33 tests)\n",
      "HK 9.6 tries (40 tests)\n",
      "LK 9.8 tries (48 tests)\n",
      "SG 10.1 tries (37 tests)\n",
      "MY 10.1 tries (34 tests)\n",
      "NG 10.2 tries (37 tests)\n",
      "PH 11.4 tries (41 tests)\n",
      ". . . . . \n",
      "Average Accuracy: 0.23454545454545456\n",
      "Averaged Average tries: 7.897773850469936\n",
      "GB 3.1 tries (326 tests)\n",
      "US 3.5 tries (332 tests)\n",
      "AU 5.0 tries (140 tests)\n",
      "IE 5.1 tries (82 tests)\n",
      "IN 5.5 tries (75 tests)\n",
      "CA 6.1 tries (120 tests)\n",
      "NZ 6.4 tries (67 tests)\n",
      "KE 7.1 tries (36 tests)\n",
      "PK 7.2 tries (55 tests)\n",
      "TZ 8.6 tries (41 tests)\n",
      "ZA 8.8 tries (35 tests)\n",
      "GH 9.3 tries (33 tests)\n",
      "HK 9.3 tries (40 tests)\n",
      "BD 9.7 tries (38 tests)\n",
      "SG 9.7 tries (37 tests)\n",
      "JM 9.9 tries (33 tests)\n",
      "LK 10.5 tries (48 tests)\n",
      "MY 10.6 tries (34 tests)\n",
      "NG 11.0 tries (37 tests)\n",
      "PH 11.4 tries (41 tests)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression model with class weights balanced\n",
    "model = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "average_performance(model, X)\n",
    "average_performance(model, X_25)\n",
    "average_performance(model, X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . \n",
      "Average Accuracy: 0.333939393939394\n",
      "Averaged Average tries: 6.543373392699858\n",
      "GB 1.4 tries (326 tests)\n",
      "US 1.5 tries (332 tests)\n",
      "IE 2.9 tries (82 tests)\n",
      "AU 3.4 tries (140 tests)\n",
      "CA 3.7 tries (120 tests)\n",
      "IN 4.3 tries (75 tests)\n",
      "JM 5.3 tries (33 tests)\n",
      "BD 5.5 tries (38 tests)\n",
      "NZ 6.5 tries (67 tests)\n",
      "LK 6.6 tries (48 tests)\n",
      "PK 7.4 tries (55 tests)\n",
      "GH 8.1 tries (33 tests)\n",
      "NG 8.2 tries (37 tests)\n",
      "HK 8.5 tries (40 tests)\n",
      "KE 8.5 tries (36 tests)\n",
      "SG 8.9 tries (37 tests)\n",
      "ZA 9.1 tries (35 tests)\n",
      "MY 9.5 tries (34 tests)\n",
      "TZ 10.4 tries (41 tests)\n",
      "PH 11.2 tries (41 tests)\n",
      ". . . . . \n",
      "Average Accuracy: 0.3381818181818182\n",
      "Averaged Average tries: 6.8401225166525705\n",
      "GB 1.5 tries (326 tests)\n",
      "US 1.5 tries (332 tests)\n",
      "IE 3.3 tries (82 tests)\n",
      "AU 3.4 tries (140 tests)\n",
      "CA 4.3 tries (120 tests)\n",
      "IN 4.4 tries (75 tests)\n",
      "BD 5.1 tries (38 tests)\n",
      "NZ 6.4 tries (67 tests)\n",
      "SG 7.1 tries (37 tests)\n",
      "GH 7.3 tries (33 tests)\n",
      "LK 7.6 tries (48 tests)\n",
      "PK 7.9 tries (55 tests)\n",
      "NG 8.0 tries (37 tests)\n",
      "KE 8.8 tries (36 tests)\n",
      "JM 8.9 tries (33 tests)\n",
      "HK 9.2 tries (40 tests)\n",
      "ZA 9.3 tries (35 tests)\n",
      "TZ 10.0 tries (41 tests)\n",
      "PH 11.1 tries (41 tests)\n",
      "MY 11.6 tries (34 tests)\n",
      ". . . . . \n",
      "Average Accuracy: 0.28363636363636363\n",
      "Averaged Average tries: 8.157452495539875\n",
      "GB 1.4 tries (326 tests)\n",
      "US 1.6 tries (332 tests)\n",
      "AU 3.5 tries (140 tests)\n",
      "IE 4.3 tries (82 tests)\n",
      "CA 4.3 tries (120 tests)\n",
      "IN 4.6 tries (75 tests)\n",
      "NZ 6.2 tries (67 tests)\n",
      "PK 7.9 tries (55 tests)\n",
      "SG 8.3 tries (37 tests)\n",
      "HK 9.2 tries (40 tests)\n",
      "NG 10.0 tries (37 tests)\n",
      "JM 10.2 tries (33 tests)\n",
      "KE 10.3 tries (36 tests)\n",
      "GH 10.5 tries (33 tests)\n",
      "ZA 11.0 tries (35 tests)\n",
      "BD 11.2 tries (38 tests)\n",
      "LK 11.7 tries (48 tests)\n",
      "PH 12.1 tries (41 tests)\n",
      "MY 12.1 tries (34 tests)\n",
      "TZ 12.8 tries (41 tests)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Classifier with class weights balanced\n",
    "rf_model = RandomForestClassifier(random_state=3, class_weight='balanced')\n",
    "average_performance(rf_model, X)\n",
    "average_performance(rf_model, X_25)\n",
    "average_performance(rf_model, X_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . \n",
      "Average Accuracy: 0.3115151515151515\n",
      "Averaged Average tries: 7.331611124639485\n",
      "GB 2.0 tries (326 tests)\n",
      "US 2.5 tries (332 tests)\n",
      "CA 3.5 tries (120 tests)\n",
      "IN 4.2 tries (75 tests)\n",
      "IE 4.3 tries (82 tests)\n",
      "AU 4.3 tries (140 tests)\n",
      "JM 5.2 tries (33 tests)\n",
      "NZ 7.3 tries (67 tests)\n",
      "HK 7.9 tries (40 tests)\n",
      "SG 8.1 tries (37 tests)\n",
      "PH 8.2 tries (41 tests)\n",
      "PK 8.6 tries (55 tests)\n",
      "LK 8.7 tries (48 tests)\n",
      "TZ 8.9 tries (41 tests)\n",
      "BD 9.0 tries (38 tests)\n",
      "KE 9.3 tries (36 tests)\n",
      "ZA 10.4 tries (35 tests)\n",
      "MY 11.2 tries (34 tests)\n",
      "NG 11.3 tries (37 tests)\n",
      "GH 11.9 tries (33 tests)\n",
      ". . . . . \n",
      "Average Accuracy: 0.3115151515151515\n",
      "Averaged Average tries: 7.331611124639485\n",
      "GB 2.0 tries (326 tests)\n",
      "US 2.5 tries (332 tests)\n",
      "CA 3.5 tries (120 tests)\n",
      "IN 4.2 tries (75 tests)\n",
      "IE 4.3 tries (82 tests)\n",
      "AU 4.3 tries (140 tests)\n",
      "JM 5.2 tries (33 tests)\n",
      "NZ 7.3 tries (67 tests)\n",
      "HK 7.9 tries (40 tests)\n",
      "SG 8.1 tries (37 tests)\n",
      "PH 8.2 tries (41 tests)\n",
      "PK 8.6 tries (55 tests)\n",
      "LK 8.7 tries (48 tests)\n",
      "TZ 8.9 tries (41 tests)\n",
      "BD 9.0 tries (38 tests)\n",
      "KE 9.3 tries (36 tests)\n",
      "ZA 10.4 tries (35 tests)\n",
      "MY 11.2 tries (34 tests)\n",
      "NG 11.3 tries (37 tests)\n",
      "GH 11.9 tries (33 tests)\n",
      ". . . . . \n",
      "Average Accuracy: 0.3115151515151515\n",
      "Averaged Average tries: 7.331611124639485\n",
      "GB 2.0 tries (326 tests)\n",
      "US 2.5 tries (332 tests)\n",
      "CA 3.5 tries (120 tests)\n",
      "IN 4.2 tries (75 tests)\n",
      "IE 4.3 tries (82 tests)\n",
      "AU 4.3 tries (140 tests)\n",
      "JM 5.2 tries (33 tests)\n",
      "NZ 7.3 tries (67 tests)\n",
      "HK 7.9 tries (40 tests)\n",
      "SG 8.1 tries (37 tests)\n",
      "PH 8.2 tries (41 tests)\n",
      "PK 8.6 tries (55 tests)\n",
      "LK 8.7 tries (48 tests)\n",
      "TZ 8.9 tries (41 tests)\n",
      "BD 9.0 tries (38 tests)\n",
      "KE 9.3 tries (36 tests)\n",
      "ZA 10.4 tries (35 tests)\n",
      "MY 11.2 tries (34 tests)\n",
      "NG 11.3 tries (37 tests)\n",
      "GH 11.9 tries (33 tests)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Multi-layer Perceptron Model\n",
    "mlp_model = MLPClassifier(random_state=3)\n",
    "average_performance(mlp_model,X)\n",
    "average_performance(mlp_model,X)\n",
    "average_performance(mlp_model,X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
